{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ```deepchem```: Machine Learning models for Drug Discovery\n",
    "#Tutorial 1: Basic Protein-Ligand Complex Featurized Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Written by Evan Feinberg and Bharath Ramsundar\n",
    "\n",
    "Copyright 2016, Stanford University\n",
    "\n",
    "#Welcome to the ```deepchem``` tutorial. In this iPython Notebook, one can follow along with the code below to learn how to fit machine learning models with rich predictive power on chemical datasets.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview:\n",
    "\n",
    "In this tutorial, you will trace an arc from loading a raw dataset to fitting a cutting edge ML technique for predicting binding affinities. This will be accomplished by writing simple commands to access the deepchem Python API, encompassing the following broad steps:\n",
    "\n",
    "1. Loading a chemical dataset, consisting of a series of protein-ligand complexes.\n",
    "2. Featurizing each protein-ligand complexes with various featurization schemes. \n",
    "3. Fitting a series of models with these featurized protein-ligand complexes.\n",
    "4. Visualizing the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's point to a \"dataset\" file. This can come in the format of a CSV file or Pandas DataFrame. Regardless\n",
    "of file format, it must be columnar data, where each row is a molecular system, and each column represents\n",
    "a different piece of information about that system. For instance, in this example, every row reflects a \n",
    "protein-ligand complex, and the following columns are present: a unique complex identifier; the SMILES string\n",
    "of the ligand; the binding affinity (Ki) of the ligand to the protein in the complex; a Python `list` of all lines\n",
    "in a PDB file for the protein alone; and a Python `list` of all lines in a ligand file for the ligand alone.\n",
    "\n",
    "This should become clearer with the example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "%pdb off\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_file= \"../datasets/pdbbind_core_df.pkl.gz\"\n",
    "from deepchem.utils.save import load_from_disk\n",
    "dataset = load_from_disk(dataset_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what `dataset` looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of dataset is: <class 'pandas.core.frame.DataFrame'>\n",
      "  pdb_id                                             smiles  \\\n",
      "0   2d3u        CC1CCCCC1S(O)(O)NC1CC(C2CCC(CN)CC2)SC1C(O)O   \n",
      "1   3cyx  CC(C)(C)NC(O)C1CC2CCCCC2C[NH+]1CC(O)C(CC1CCCCC...   \n",
      "2   3uo4        OC(O)C1CCC(NC2NCCC(NC3CCCCC3C3CCCCC3)N2)CC1   \n",
      "3   1p1q                         CC1ONC(O)C1CC([NH3+])C(O)O   \n",
      "4   3ag9  NC(O)C(CCC[NH2+]C([NH3+])[NH3+])NC(O)C(CCC[NH2...   \n",
      "\n",
      "                                          complex_id  \\\n",
      "0    2d3uCC1CCCCC1S(O)(O)NC1CC(C2CCC(CN)CC2)SC1C(O)O   \n",
      "1  3cyxCC(C)(C)NC(O)C1CC2CCCCC2C[NH+]1CC(O)C(CC1C...   \n",
      "2    3uo4OC(O)C1CCC(NC2NCCC(NC3CCCCC3C3CCCCC3)N2)CC1   \n",
      "3                     1p1qCC1ONC(O)C1CC([NH3+])C(O)O   \n",
      "4  3ag9NC(O)C(CCC[NH2+]C([NH3+])[NH3+])NC(O)C(CCC...   \n",
      "\n",
      "                                         protein_pdb  \\\n",
      "0  [HEADER    2D3U PROTEIN\\n, COMPND    2D3U PROT...   \n",
      "1  [HEADER    3CYX PROTEIN\\n, COMPND    3CYX PROT...   \n",
      "2  [HEADER    3UO4 PROTEIN\\n, COMPND    3UO4 PROT...   \n",
      "3  [HEADER    1P1Q PROTEIN\\n, COMPND    1P1Q PROT...   \n",
      "4  [HEADER    3AG9 PROTEIN\\n, COMPND    3AG9 PROT...   \n",
      "\n",
      "                                          ligand_pdb  \\\n",
      "0  [COMPND    2d3u ligand \\n, AUTHOR    GENERATED...   \n",
      "1  [COMPND    3cyx ligand \\n, AUTHOR    GENERATED...   \n",
      "2  [COMPND    3uo4 ligand \\n, AUTHOR    GENERATED...   \n",
      "3  [COMPND    1p1q ligand \\n, AUTHOR    GENERATED...   \n",
      "4  [COMPND    3ag9 ligand \\n, AUTHOR    GENERATED...   \n",
      "\n",
      "                                         ligand_mol2 label  \n",
      "0  [### \\n, ### Created by X-TOOL on Thu Aug 28 2...  6.92  \n",
      "1  [### \\n, ### Created by X-TOOL on Thu Aug 28 2...  8.00  \n",
      "2  [### \\n, ### Created by X-TOOL on Fri Aug 29 0...  6.52  \n",
      "3  [### \\n, ### Created by X-TOOL on Thu Aug 28 2...  4.89  \n",
      "4  [### \\n, ### Created by X-TOOL on Thu Aug 28 2...  8.05  \n",
      "Shape of dataset is: (193, 7)\n"
     ]
    }
   ],
   "source": [
    "print(\"Type of dataset is: %s\" % str(type(dataset)))\n",
    "print(dataset[:5])\n",
    "print(\"Shape of dataset is: %s\" % str(dataset.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the missions of ```deepchem``` is to form a synapse between the chemical and the algorithmic worlds: to be able to leverage the powerful and diverse array of tools available in Python to analyze molecules. This ethos applies to visual as much as quantitative examination:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nglview\n",
    "import tempfile\n",
    "import os\n",
    "import mdtraj as md\n",
    "import numpy as np\n",
    "import deepchem.utils.visualization\n",
    "reload(deepchem.utils.visualization)\n",
    "from deepchem.utils.visualization import combine_mdtraj, visualize_complex, convert_lines_to_mdtraj\n",
    "\n",
    "first_protein, first_ligand = dataset.iloc[0][\"protein_pdb\"], dataset.iloc[0][\"ligand_pdb\"]\n",
    "\n",
    "protein_mdtraj = convert_lines_to_mdtraj(first_protein)\n",
    "ligand_mdtraj = convert_lines_to_mdtraj(first_ligand)\n",
    "complex_mdtraj = combine_mdtraj(protein_mdtraj, ligand_mdtraj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualize_complex(complex_mdtraj):\n",
    "  ligand_atoms = [a.index for a in complex_mdtraj.topology.atoms if \"LIG\" in str(a.residue)]\n",
    "  binding_pocket_atoms = md.compute_neighbors(complex_mdtraj, 0.5, ligand_atoms)[0]\n",
    "  binding_pocket_residues = list(set([complex_mdtraj.topology.atom(a).residue.resSeq for a in binding_pocket_atoms]))\n",
    "  binding_pocket_residues = [str(r) for r in binding_pocket_residues]\n",
    "  binding_pocket_residues = \" or \".join(binding_pocket_residues)\n",
    "\n",
    "  traj = nglview.MDTrajTrajectory( complex_mdtraj ) # load file from RCSB PDB\n",
    "  ngltraj = nglview.NGLWidget( traj )\n",
    "  ngltraj.representations = [\n",
    "  { \"type\": \"cartoon\", \"params\": {\n",
    "  \"sele\": \"protein\", \"color\": \"residueindex\"\n",
    "  } },\n",
    "  { \"type\": \"licorice\", \"params\": {\n",
    "  \"sele\": \"(not hydrogen) and (resi (%s))\" %  binding_pocket_residues\n",
    "  } },\n",
    "  { \"type\": \"ball+stick\", \"params\": {\n",
    "  \"sele\": \"resn LIG\"\n",
    "  } }\n",
    "  ]\n",
    "  return ngltraj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/enf/anaconda/lib/python2.7/site-packages/ipywidgets/widgets/widget.py:157: DeprecationWarning: Widget._keys_default is deprecated: use @default decorator instead.\n",
      "  def _keys_default(self):\n",
      "/home/enf/anaconda/lib/python2.7/site-packages/ipywidgets/widgets/widget.py:157: DeprecationWarning: Widget._keys_default is deprecated: use @default decorator instead.\n",
      "  def _keys_default(self):\n",
      "/home/enf/anaconda/lib/python2.7/site-packages/ipykernel/comm/comm.py:52: DeprecationWarning: Comm._comm_id_default is deprecated: use @default decorator instead.\n",
      "  def _comm_id_default(self):\n",
      "/home/enf/anaconda/lib/python2.7/site-packages/ipykernel/comm/comm.py:29: DeprecationWarning: Comm._iopub_socket_default is deprecated: use @default decorator instead.\n",
      "  def _iopub_socket_default(self):\n",
      "/home/enf/anaconda/lib/python2.7/site-packages/ipykernel/comm/comm.py:24: DeprecationWarning: Comm._kernel_default is deprecated: use @default decorator instead.\n",
      "  def _kernel_default(self):\n",
      "/home/enf/anaconda/lib/python2.7/site-packages/ipykernel/comm/comm.py:32: DeprecationWarning: Comm._session_default is deprecated: use @default decorator instead.\n",
      "  def _session_default(self):\n",
      "/home/enf/anaconda/lib/python2.7/site-packages/ipykernel/comm/comm.py:41: DeprecationWarning: Comm._topic_default is deprecated: use @default decorator instead.\n",
      "  def _topic_default(self):\n",
      "/home/enf/anaconda/lib/python2.7/site-packages/ipykernel/comm/comm.py:24: DeprecationWarning: Comm._kernel_default is deprecated: use @default decorator instead.\n",
      "  def _kernel_default(self):\n",
      "/home/enf/anaconda/lib/python2.7/site-packages/ipykernel/comm/comm.py:52: DeprecationWarning: Comm._comm_id_default is deprecated: use @default decorator instead.\n",
      "  def _comm_id_default(self):\n",
      "/home/enf/anaconda/lib/python2.7/site-packages/ipykernel/comm/manager.py:37: DeprecationWarning: CommManager._iopub_socket_default is deprecated: use @default decorator instead.\n",
      "  def _iopub_socket_default(self):\n",
      "/home/enf/anaconda/lib/python2.7/site-packages/ipykernel/comm/comm.py:32: DeprecationWarning: Comm._session_default is deprecated: use @default decorator instead.\n",
      "  def _session_default(self):\n",
      "/home/enf/anaconda/lib/python2.7/site-packages/ipykernel/comm/comm.py:41: DeprecationWarning: Comm._topic_default is deprecated: use @default decorator instead.\n",
      "  def _topic_default(self):\n",
      "/home/enf/anaconda/lib/python2.7/site-packages/ipywidgets/widgets/widget.py:194: DeprecationWarning: NGLWidget._comm_changed is deprecated: use @observe and @unobserve instead.\n",
      "  def _comm_changed(self, name, new):\n",
      "/home/enf/anaconda/lib/python2.7/site-packages/ipywidgets/widgets/widget.py:513: DeprecationWarning: on_trait_change is deprecated: use observe instead\n",
      "  self.on_trait_change(_validate_border, ['border_width', 'border_style', 'border_color'])\n",
      "/home/enf/anaconda/lib/python2.7/site-packages/IPython/core/formatters.py:92: DeprecationWarning: DisplayFormatter._ipython_display_formatter_default is deprecated: use @default decorator instead.\n",
      "  def _ipython_display_formatter_default(self):\n"
     ]
    }
   ],
   "source": [
    "ngltraj = visualize_complex(complex_mdtraj)\n",
    "ngltraj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we're oriented, let's use ML to do some chemistry. \n",
    "\n",
    "So, step (2) will entail featurizing the dataset.\n",
    "\n",
    "The available featurizations that come standard with deepchem are ECFP4 fingerprints, RDKit descriptors, NNScore-style bdescriptors, and hybrid binding pocket descriptors. Details can be found on ```deepchem.io```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from deepchem.featurizers.fingerprints import CircularFingerprint\n",
    "from deepchem.featurizers.basic import RDKitDescriptors\n",
    "from deepchem.featurizers.nnscore import NNScoreComplexFeaturizer\n",
    "from deepchem.featurizers.grid_featurizer import GridFeaturizer\n",
    "grid_featurizer = GridFeaturizer(voxel_width=16.0, feature_types=\"voxel_combined\", voxel_feature_types=[\"ecfp\",\n",
    "                                 \"splif\", \"hbond\", \"pi_stack\", \"cation_pi\", \"salt_bridge\"], ecfp_power=5, splif_power=5,\n",
    "                                 parallel=True, flatten=True)\n",
    "compound_featurizers = [CircularFingerprint(size=128)]\n",
    "complex_featurizers = [grid_featurizer]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how we separate our featurizers into those that featurize individual chemical compounds, compound_featurizers, and those that featurize molecular complexes, complex_featurizers.\n",
    "\n",
    "Now, let's perform the actual featurization. Calling ```featurizer.featurize()``` will return an instance of class ```FeaturizedSamples```. Internally, ```featurizer.featurize()``` (a) computes the user-specified features on the data, (b) transforms the inputs into X and y NumPy arrays suitable for ML algorithms, and (c) constructs a ```FeaturizedSamples()``` instance that has useful methods, such as an iterator, over the featurized data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Make a directory in which to store the featurized complexes.\n",
    "import tempfile, shutil\n",
    "base_dir = \"./tutorial_output\"\n",
    "if not os.path.exists(base_dir):\n",
    "    os.makedirs(base_dir)\n",
    "data_dir = os.path.join(base_dir, \"data\")\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "    \n",
    "featurized_samples_file = os.path.join(data_dir, \"featurized_samples.joblib\")\n",
    "\n",
    "feature_dir = os.path.join(base_dir, \"features\")\n",
    "if not os.path.exists(feature_dir):\n",
    "    os.makedirs(feature_dir)\n",
    "\n",
    "samples_dir = os.path.join(base_dir, \"samples\")\n",
    "if not os.path.exists(samples_dir):\n",
    "    os.makedirs(samples_dir)\n",
    "\n",
    "train_dir = os.path.join(base_dir, \"train\")\n",
    "if not os.path.exists(train_dir):\n",
    "    os.makedirs(train_dir)\n",
    "\n",
    "valid_dir = os.path.join(base_dir, \"valid\")\n",
    "if not os.path.exists(valid_dir):\n",
    "    os.makedirs(valid_dir)\n",
    "\n",
    "test_dir = os.path.join(base_dir, \"test\")\n",
    "if not os.path.exists(test_dir):\n",
    "    os.makedirs(test_dir)\n",
    "\n",
    "model_dir = os.path.join(base_dir, \"model\")\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import deepchem.featurizers.featurize\n",
    "reload(deepchem.featurizers.featurize)\n",
    "from deepchem.featurizers.featurize import DataFeaturizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c.ids\n",
      "[0, 1, 2, 3, 4, 5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/enf/anaconda/lib/python2.7/site-packages/ipyparallel/client/client.py:306: DeprecationWarning: Client._profile_default is deprecated: use @default decorator instead.\n",
      "  def _profile_default(self):\n",
      "/home/enf/anaconda/lib/python2.7/site-packages/ipyparallel/client/client.py:306: DeprecationWarning: Client._profile_default is deprecated: use @default decorator instead.\n",
      "  def _profile_default(self):\n",
      "/home/enf/anaconda/lib/python2.7/site-packages/IPython/core/profiledir.py:57: DeprecationWarning: ProfileDir._location_changed is deprecated: use @observe and @unobserve instead.\n",
      "  def _location_changed(self, name, old, new):\n",
      "/home/enf/anaconda/lib/python2.7/site-packages/IPython/core/profiledir.py:126: DeprecationWarning: ProfileDir._security_dir_changed is deprecated: use @observe and @unobserve instead.\n",
      "  def _security_dir_changed(self, name, old, new):\n",
      "/home/enf/anaconda/lib/python2.7/site-packages/IPython/core/profiledir.py:71: DeprecationWarning: ProfileDir._log_dir_changed is deprecated: use @observe and @unobserve instead.\n",
      "  def _log_dir_changed(self, name, old, new):\n",
      "/home/enf/anaconda/lib/python2.7/site-packages/IPython/core/profiledir.py:111: DeprecationWarning: ProfileDir._startup_dir_changed is deprecated: use @observe and @unobserve instead.\n",
      "  def _startup_dir_changed(self, name, old, new):\n",
      "/home/enf/anaconda/lib/python2.7/site-packages/IPython/core/profiledir.py:132: DeprecationWarning: ProfileDir._pid_dir_changed is deprecated: use @observe and @unobserve instead.\n",
      "  def _pid_dir_changed(self, name, old, new):\n",
      "/home/enf/anaconda/lib/python2.7/site-packages/IPython/core/profiledir.py:138: DeprecationWarning: ProfileDir._static_dir_changed is deprecated: use @observe and @unobserve instead.\n",
      "  def _static_dir_changed(self, name, old, new):\n",
      "/home/enf/anaconda/lib/python2.7/site-packages/jupyter_client/session.py:351: DeprecationWarning: Session._digest_mod_default is deprecated: use @default decorator instead.\n",
      "  def _digest_mod_default(self):\n",
      "/home/enf/anaconda/lib/python2.7/site-packages/jupyter_client/session.py:331: DeprecationWarning: Session._key_default is deprecated: use @default decorator instead.\n",
      "  def _key_default(self):\n",
      "/home/enf/anaconda/lib/python2.7/site-packages/jupyter_client/session.py:306: DeprecationWarning: Session._session_default is deprecated: use @default decorator instead.\n",
      "  def _session_default(self):\n",
      "/home/enf/anaconda/lib/python2.7/site-packages/jupyter_client/session.py:334: DeprecationWarning: Session._key_changed is deprecated: use @observe and @unobserve instead.\n",
      "  def _key_changed(self):\n",
      "/home/enf/anaconda/lib/python2.7/site-packages/jupyter_client/session.py:351: DeprecationWarning: Session._digest_mod_default is deprecated: use @default decorator instead.\n",
      "  def _digest_mod_default(self):\n",
      "/home/enf/anaconda/lib/python2.7/site-packages/jupyter_client/session.py:306: DeprecationWarning: Session._session_default is deprecated: use @default decorator instead.\n",
      "  def _session_default(self):\n"
     ]
    }
   ],
   "source": [
    "featurizers = compound_featurizers + complex_featurizers\n",
    "featurizer = DataFeaturizer(tasks=[\"label\"],\n",
    "                            smiles_field=\"smiles\",\n",
    "                            protein_pdb_field=\"protein_pdb\",\n",
    "                            ligand_pdb_field=\"ligand_pdb\",\n",
    "                            compound_featurizers=compound_featurizers,\n",
    "                            complex_featurizers=[],\n",
    "                            id_field=\"complex_id\",\n",
    "                            verbose=False)\n",
    "from ipyparallel import Client\n",
    "c = Client()\n",
    "print(\"c.ids\")\n",
    "print(c.ids)\n",
    "dview = c[:]\n",
    "featurized_samples = featurizer.featurize(dataset_file, feature_dir, samples_dir,\n",
    "                                          worker_pool=dview, shard_size=32)\n",
    "\n",
    "from deepchem.utils.save import save_to_disk, load_from_disk\n",
    "\n",
    "save_to_disk(featurized_samples, featurized_samples_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featurized_samples = load_from_disk(featurized_samples_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we conduct a train-test split. If you'd like, you can choose `splittype=\"scaffold\"` instead to perform a train-test split based on Bemis-Murcko scaffolds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/users/enf/deep-docking/deepchem/deepchem/featurizers/featurize.py:470: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  return (shuffled[:train_cutoff], shuffled[train_cutoff:valid_cutoff],\n",
      "/scratch/users/enf/deep-docking/deepchem/deepchem/featurizers/featurize.py:470: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  return (shuffled[:train_cutoff], shuffled[train_cutoff:valid_cutoff],\n",
      "/scratch/users/enf/deep-docking/deepchem/deepchem/featurizers/featurize.py:470: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  return (shuffled[:train_cutoff], shuffled[train_cutoff:valid_cutoff],\n",
      "/scratch/users/enf/deep-docking/deepchem/deepchem/featurizers/featurize.py:471: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  shuffled[valid_cutoff:])\n"
     ]
    }
   ],
   "source": [
    "splittype = \"random\"\n",
    "\n",
    "train_samples, test_samples = featurized_samples.train_test_split(\n",
    "    splittype, train_dir, test_dir, seed=2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate separate instances of the Dataset() object to hermetically seal the train dataset from the test dataset. This style lends itself easily to validation-set type hyperparameter searches, which we will illustate in a separate section of this tutorial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from deepchem.utils.dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_dataset = Dataset(data_dir=train_dir, samples=train_samples, \n",
    "                        featurizers=compound_featurizers, tasks=[\"label\"])\n",
    "test_dataset = Dataset(data_dir=test_dir, samples=test_samples, \n",
    "                       featurizers=compound_featurizers, tasks=[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of many ML algorithms hinges greatly on careful data preprocessing. Deepchem comes standard with a few options for such preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_transforms = [\"normalize\", \"truncate\"]\n",
    "output_transforms = [\"normalize\"]\n",
    "train_dataset.transform(input_transforms, output_transforms)\n",
    "test_dataset.transform(input_transforms, output_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we're ready to do some learning! To set up a model, we will need: (a) a dictionary ```task_types``` that maps a task, in this case ```label```, i.e. the Ki, to the type of the task, in this case ```regression```. For the multitask use case, one will have a series of keys, each of which is a different task (Ki, solubility, renal half-life, etc.) that maps to a different task type (regression or classification).\n",
    "\n",
    "To fit a deepchem model, first we instantiate one of the provided (or user-written) model classes. In this case, we have a created a convenience class to wrap around any ML model available in Sci-Kit Learn that can in turn be used to interoperate with deepchem. To instantiate an ```SklearnModel```, you will need (a) task_types, (b) model_params, another ```dict``` as illustrated below, and (c) a ```model_instance``` defining the type of model you would like to fit, in this case a ```RandomForestRegressor```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from deepchem.models.standard import SklearnModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "task_types = {\"label\": \"regression\"}\n",
    "model_params = {\"data_shape\": train_dataset.get_data_shape()}\n",
    "\n",
    "model = SklearnModel(task_types, model_params, model_instance=RandomForestRegressor())\n",
    "model.fit(train_dataset)\n",
    "model_dir = tempfile.mkdtemp()\n",
    "model.save(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from deepchem.utils.evaluate import Evaluator\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving predictions to <open file '<fdopen>', mode 'w+b' at 0x7f42c787d390>\n",
      "Saving model performance scores to <open file '<fdopen>', mode 'w+b' at 0x7f42c787d540>\n",
      "Saving predictions to <open file '<fdopen>', mode 'w+b' at 0x7f42c787d4b0>\n",
      "Saving model performance scores to <open file '<fdopen>', mode 'w+b' at 0x7f42c787d780>\n",
      "/local-scratch/enf/7438120/tmp1Yjtiz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/enf/anaconda/lib/python2.7/site-packages/IPython/core/formatters.py:98: DeprecationWarning: DisplayFormatter._formatters_default is deprecated: use @default decorator instead.\n",
      "  def _formatters_default(self):\n",
      "/home/enf/anaconda/lib/python2.7/site-packages/IPython/core/formatters.py:677: DeprecationWarning: PlainTextFormatter._deferred_printers_default is deprecated: use @default decorator instead.\n",
      "  def _deferred_printers_default(self):\n",
      "/home/enf/anaconda/lib/python2.7/site-packages/IPython/core/formatters.py:669: DeprecationWarning: PlainTextFormatter._singleton_printers_default is deprecated: use @default decorator instead.\n",
      "  def _singleton_printers_default(self):\n",
      "/home/enf/anaconda/lib/python2.7/site-packages/IPython/core/formatters.py:672: DeprecationWarning: PlainTextFormatter._type_printers_default is deprecated: use @default decorator instead.\n",
      "  def _type_printers_default(self):\n",
      "/home/enf/anaconda/lib/python2.7/site-packages/IPython/core/formatters.py:669: DeprecationWarning: PlainTextFormatter._singleton_printers_default is deprecated: use @default decorator instead.\n",
      "  def _singleton_printers_default(self):\n",
      "/home/enf/anaconda/lib/python2.7/site-packages/IPython/core/formatters.py:672: DeprecationWarning: PlainTextFormatter._type_printers_default is deprecated: use @default decorator instead.\n",
      "  def _type_printers_default(self):\n",
      "/home/enf/anaconda/lib/python2.7/site-packages/IPython/core/formatters.py:677: DeprecationWarning: PlainTextFormatter._deferred_printers_default is deprecated: use @default decorator instead.\n",
      "  def _deferred_printers_default(self):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_name</th>\n",
       "      <th>r2_score</th>\n",
       "      <th>rms_error</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>label</td>\n",
       "      <td>0.806727</td>\n",
       "      <td>0.988301</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>label</td>\n",
       "      <td>0.342652</td>\n",
       "      <td>1.805124</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  task_name  r2_score  rms_error  split\n",
       "0     label  0.806727   0.988301  train\n",
       "0     label  0.342652   1.805124   test"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = Evaluator(model, train_dataset, verbose=True)\n",
    "with tempfile.NamedTemporaryFile() as train_csv_out:\n",
    "  with tempfile.NamedTemporaryFile() as train_stats_out:\n",
    "    _, train_r2score = evaluator.compute_model_performance(\n",
    "        train_csv_out, train_stats_out)\n",
    "\n",
    "evaluator = Evaluator(model, test_dataset, verbose=True)\n",
    "test_csv_out = tempfile.NamedTemporaryFile()\n",
    "with tempfile.NamedTemporaryFile() as test_stats_out:\n",
    "    _, test_r2score = evaluator.compute_model_performance(\n",
    "        test_csv_out, test_stats_out)\n",
    "\n",
    "print test_csv_out.name\n",
    "train_test_performance = pd.concat([train_r2score, test_r2score])\n",
    "train_test_performance[\"split\"] = [\"train\", \"test\"]\n",
    "train_test_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this simple example, in few yet intuitive lines of code, we traced the machine learning arc from featurizing a raw dataset to fitting and evaluating a model. \n",
    "\n",
    "Here, we featurized only the ligand. The signal we observed in R^2 reflects the ability of circular fingerprints and random forests to learn general features that make ligands \"drug-like.\"\n",
    "\n",
    "Let's take a quick look at what the algorithm determines to be high- and low-affinity drugs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Unnamed: 0                                                ids     label  \\\n",
      "0            0    2d3uCC1CCCCC1S(O)(O)NC1CC(C2CCC(CN)CC2)SC1C(O)O  0.577883   \n",
      "1            1  3cyxCC(C)(C)NC(O)C1CC2CCCCC2C[NH+]1CC(O)C(CC1C...  1.142494   \n",
      "2           24                      2zxdCC(C)C1[NH2+]CC(O)C(O)C1O -0.310858   \n",
      "3           25                     3bfu[NH3+]C(CC1NSNC1O)C([O-])O  0.238070   \n",
      "4           28                                 3u9qCCCCCCCCCC(O)O -0.750001   \n",
      "5           44              3l7bNC1CCN(C2OC(CO)C(O)C(F)C2O)C(O)N1 -1.785122   \n",
      "6           45  3oztOC(NCCCC1OC(N2CCC(O)CC2)C(O)C1O)C1CC(N(O)O... -0.880698   \n",
      "7           49  3ivgCOC1CCC2C(CC(CNS(O)(O)C3CC4CCCCC4O3)N2CC(O... -0.791824   \n",
      "8           54  1sqa[NH3+]CC1CCC(NC(O)C2CC3CCC(C([NH3+])[NH3+]...  1.775069   \n",
      "9           56                     2xdlCCN(CC)C(O)C1CCC(O)C(OC)C1 -1.419170   \n",
      "10          57                      3udhOC1NC2CCCCC2C12CC[NH2+]C2 -1.549867   \n",
      "11          73         1w4oOCC1OC(N2CCC(O)NC2O)C(O)C1O[PH](O)(O)O -0.310858   \n",
      "12          76                               3gy4NC(N)C1CCC(N)CC1 -0.373593   \n",
      "13          78                          3b3wCC(C)CC([NH3+])C(=O)O -0.849330   \n",
      "14          80       2zjwOC1CC2C(O)OC3C(O)C(O)CC4C(O)OC(C1O)C2C43  0.985658   \n",
      "15          83  1os0[NH3+]C(CC1CCCCC1)[PH](O)(O)CC(CC1CCCCC1)C...  0.112601   \n",
      "16          92          3acwOC1(C2CCC(C3CCCCC3)CC2)C[NH+]2CCC1CC2 -0.551341   \n",
      "17          98           3mssCNC(O)C([NH3+])CC1CCC(OCC2CCCCC2)CC1 -0.603620   \n",
      "18         107  2p4yCOC1CCC2C(C1)ONC2C1C(C)N(CC2CC(OC(C)C([O-]...  1.665283   \n",
      "19         108                       3d4zOCC1C(O)C(O)C(O)C2NCCN21 -0.483378   \n",
      "20         110                     3mfvNC1NCC(CCC([NH3+])C(O)O)N1 -1.722388   \n",
      "21         112        1f8dCC(O)NC1C(O)CC(C(O)O)OC1C(O)C(O)C[NH3+] -1.262334   \n",
      "22         117  3nw9CC1NCNC2C1NCN2C1OC(CCCNC(O)C2CC(C3CCC(F)CC...  1.665283   \n",
      "23         131               3ehyCOC1CCC(S(O)(O)NC(C)C([O-])O)CC1  0.018499   \n",
      "24         132  3ov1CC(O)NC(CC1CCC(O[PH](O)(O)O)CC1)C(O)NC1(C(... -0.321314   \n",
      "25         133         4de1OC(NC1CCCC(C2[N-]NNN2)C1)C1CCC2NNCC2C1  0.076005   \n",
      "26         136  2xnbCC1C(C2CCNC(NC3CCC(N4CC[NH2+]CC4)CC3)N2)SC...  0.530832   \n",
      "27         139    2obfOCC1CC2CCC(S(O)(O)NC3CCC(Cl)CC3)CC2C[NH2+]1  1.586865   \n",
      "28         154  3l3n[NH3+]CCCCC([NH2+]C(CCC1CCCCC1)C(O)O)C(O)N...  1.236596   \n",
      "29         158                                3vh9OC1CCCC2CCCNC12  0.222386   \n",
      "30         161                          2jdyCOC1OC(CO)C(O)C(O)C1O -0.755229   \n",
      "31         174                        1n2vCCCCC1NC2C(N1)C(O)NNC2O -0.906837   \n",
      "32         175           2votOCC1C(O)C(O)C(O)C2NC(CNC3CCCCC3)CN21  0.692896   \n",
      "33         178                      3n7a[O-]C(O)C1(O)CCC(O)C(O)C1 -1.105497   \n",
      "\n",
      "    label_pred  label_weight   y_means    y_stds  \n",
      "0    -0.276078             1  5.814615  1.912819  \n",
      "1     0.617702             1  5.814615  1.912819  \n",
      "2    -0.122412             1  5.814615  1.912819  \n",
      "3    -0.169293             1  5.814615  1.912819  \n",
      "4    -0.804344             1  5.814615  1.912819  \n",
      "5    -0.818249             1  5.814615  1.912819  \n",
      "6     0.258280             1  5.814615  1.912819  \n",
      "7    -0.275210             1  5.814615  1.912819  \n",
      "8     0.015193             1  5.814615  1.912819  \n",
      "9     0.054695             1  5.814615  1.912819  \n",
      "10    0.007379             1  5.814615  1.912819  \n",
      "11   -1.417286             1  5.814615  1.912819  \n",
      "12   -0.110257             1  5.814615  1.912819  \n",
      "13   -0.996477             1  5.814615  1.912819  \n",
      "14   -0.187090             1  5.814615  1.912819  \n",
      "15   -0.009116             1  5.814615  1.912819  \n",
      "16   -0.614229             1  5.814615  1.912819  \n",
      "17   -0.004775             1  5.814615  1.912819  \n",
      "18    0.971047             1  5.814615  1.912819  \n",
      "19   -0.298650             1  5.814615  1.912819  \n",
      "20   -0.248730             1  5.814615  1.912819  \n",
      "21   -0.250467             1  5.814615  1.912819  \n",
      "22    0.432782             1  5.814615  1.912819  \n",
      "23    0.060338             1  5.814615  1.912819  \n",
      "24    1.404046             1  5.814615  1.912819  \n",
      "25    0.669358             1  5.814615  1.912819  \n",
      "26    0.748796             1  5.814615  1.912819  \n",
      "27    0.014759             1  5.814615  1.912819  \n",
      "28    0.317316             1  5.814615  1.912819  \n",
      "29   -0.547380             1  5.814615  1.912819  \n",
      "30   -0.352911             1  5.814615  1.912819  \n",
      "31   -0.695403             1  5.814615  1.912819  \n",
      "32   -0.112862             1  5.814615  1.912819  \n",
      "33   -0.376264             1  5.814615  1.912819  \n"
     ]
    }
   ],
   "source": [
    "predictions = pd.read_csv(test_csv_out.name)\n",
    "print(predictions)\n",
    "predictions = predictions.sort(['label'], ascending=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_ligand = predictions.iloc[0]['ids']\n",
    "ligand1 = convert_lines_to_mdtraj(dataset.loc[dataset['complex_id']==top_ligand]['ligand_pdb'].values[0])\n",
    "\n",
    "def visualize_ligand(ligand_mdtraj):\n",
    "  traj = nglview.MDTrajTrajectory( ligand_mdtraj ) # load file from RCSB PDB\n",
    "  ngltraj = nglview.NGLWidget( traj )\n",
    "  ngltraj.representations = [\n",
    "  { \"type\": \"ball+stick\", \"params\": {\n",
    "  \"sele\": \"all\"\n",
    "  } }\n",
    "  ]\n",
    "  return ngltraj\n",
    "\n",
    "ngltraj = visualize_ligand(ligand1)\n",
    "ngltraj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "worst_ligand = predictions.iloc[predictions.shape[0]-2]['ids']\n",
    "ligand1 = convert_lines_to_mdtraj(dataset.loc[dataset['complex_id']==worst_ligand]['ligand_pdb'].values[0])\n",
    "ngltraj = visualize_ligand(ligand1)\n",
    "ngltraj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The protein-ligand complex view."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preceding simple example, in few yet intuitive lines of code, traces the machine learning arc from featurizing a raw dataset to fitting and evaluating a model. \n",
    "\n",
    "In this next section, we illustrate ```deepchem```'s modularity, and thereby the ease with which one can explore different featurization schemes, different models, and combinations thereof, to achieve the best performance on a given dataset. We will demonstrate this by examining protein-ligand interactions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous section, we featurized only the ligand. The signal we observed in R^2 reflects the ability of circular fingerprints and random forests to learn general features that make ligands \"drug-like.\" However, the affinity of a drug for a target is determined not only by the drug itself, of course, but the way in which it interacts with a protein. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving predictions to <open file '<fdopen>', mode 'w+b' at 0x7fea97ca6e40>\n",
      "Saving model performance scores to <open file '<fdopen>', mode 'w+b' at 0x7fea97ca6f60>\n",
      "Saving predictions to <open file '<fdopen>', mode 'w+b' at 0x7fea994b8810>\n",
      "Saving model performance scores to <open file '<fdopen>', mode 'w+b' at 0x7fea994b8f60>\n",
      "  task_name  r2_score  rms_error       split  \\\n",
      "0     label  0.850802   0.890800       train   \n",
      "0     label  0.380784   1.172148  validation   \n",
      "\n",
      "                                          featurizer  n_trees  \n",
      "0  <class 'deepchem.featurizers.grid_featurizer.G...       10  \n",
      "0  <class 'deepchem.featurizers.grid_featurizer.G...       10  \n",
      "Saving predictions to <open file '<fdopen>', mode 'w+b' at 0x7fea994b8b70>\n",
      "Saving model performance scores to <open file '<fdopen>', mode 'w+b' at 0x7fea97ca6e40>\n",
      "Saving predictions to <open file '<fdopen>', mode 'w+b' at 0x7fea97ca6f60>\n",
      "Saving model performance scores to <open file '<fdopen>', mode 'w+b' at 0x7fea994b8810>\n",
      "  task_name  r2_score  rms_error       split  \\\n",
      "0     label  0.877179    0.80823       train   \n",
      "0     label  0.157616    1.36715  validation   \n",
      "\n",
      "                                          featurizer  n_trees  \n",
      "0  <class 'deepchem.featurizers.grid_featurizer.G...       20  \n",
      "0  <class 'deepchem.featurizers.grid_featurizer.G...       20  \n",
      "Saving predictions to <open file '<fdopen>', mode 'w+b' at 0x7fea994b8f60>\n",
      "Saving model performance scores to <open file '<fdopen>', mode 'w+b' at 0x7fea994b8b70>\n",
      "Saving predictions to <open file '<fdopen>', mode 'w+b' at 0x7fea97ca6e40>\n",
      "Saving model performance scores to <open file '<fdopen>', mode 'w+b' at 0x7fea97ca6f60>\n",
      "  task_name  r2_score  rms_error       split  \\\n",
      "0     label  0.900207   0.728532       train   \n",
      "0     label  0.279117   1.264717  validation   \n",
      "\n",
      "                                          featurizer  n_trees  \n",
      "0  <class 'deepchem.featurizers.grid_featurizer.G...       40  \n",
      "0  <class 'deepchem.featurizers.grid_featurizer.G...       40  \n",
      "Saving predictions to <open file '<fdopen>', mode 'w+b' at 0x7fea994b8810>\n",
      "Saving model performance scores to <open file '<fdopen>', mode 'w+b' at 0x7fea994b8f60>\n",
      "Saving predictions to <open file '<fdopen>', mode 'w+b' at 0x7fea994b8b70>\n",
      "Saving model performance scores to <open file '<fdopen>', mode 'w+b' at 0x7fea97ca6e40>\n",
      "  task_name  r2_score  rms_error       split  \\\n",
      "0     label  0.895135   0.746817       train   \n",
      "0     label  0.303473   1.243169  validation   \n",
      "\n",
      "                                          featurizer  n_trees  \n",
      "0  <class 'deepchem.featurizers.grid_featurizer.G...       80  \n",
      "0  <class 'deepchem.featurizers.grid_featurizer.G...       80  \n",
      "Saving predictions to <open file '<fdopen>', mode 'w+b' at 0x7fea97ca6f60>\n",
      "Saving model performance scores to <open file '<fdopen>', mode 'w+b' at 0x7fea994b8810>\n",
      "Saving predictions to <open file '<fdopen>', mode 'w+b' at 0x7fea994b8f60>\n",
      "Saving model performance scores to <open file '<fdopen>', mode 'w+b' at 0x7fea994b8b70>\n",
      "  task_name  r2_score  rms_error       split  \\\n",
      "0     label  0.904690   0.711980       train   \n",
      "0     label  0.275001   1.268323  validation   \n",
      "\n",
      "                                          featurizer  n_trees  \n",
      "0  <class 'deepchem.featurizers.grid_featurizer.G...      160  \n",
      "0  <class 'deepchem.featurizers.grid_featurizer.G...      160  \n",
      "Saving predictions to <open file '<fdopen>', mode 'w+b' at 0x7fea97ca6e40>\n",
      "Saving model performance scores to <open file '<fdopen>', mode 'w+b' at 0x7fea97ca6f60>\n",
      "Saving predictions to <open file '<fdopen>', mode 'w+b' at 0x7fea994b8810>\n",
      "Saving model performance scores to <open file '<fdopen>', mode 'w+b' at 0x7fea994b8f60>\n",
      "  task_name  r2_score  rms_error       split  \\\n",
      "0     label  0.818402   0.982774       train   \n",
      "0     label  0.045733   1.455111  validation   \n",
      "\n",
      "                                          featurizer  n_trees  \n",
      "0  <class 'deepchem.featurizers.fingerprints.Circ...       10  \n",
      "0  <class 'deepchem.featurizers.fingerprints.Circ...       10  \n",
      "Saving predictions to <open file '<fdopen>', mode 'w+b' at 0x7fea994b8b70>\n",
      "Saving model performance scores to <open file '<fdopen>', mode 'w+b' at 0x7fea97ca6e40>\n",
      "Saving predictions to <open file '<fdopen>', mode 'w+b' at 0x7fea97ca6f60>\n",
      "Saving model performance scores to <open file '<fdopen>', mode 'w+b' at 0x7fea994b8810>\n",
      "  task_name  r2_score  rms_error       split  \\\n",
      "0     label  0.837979   0.928291       train   \n",
      "0     label  0.257332   1.283685  validation   \n",
      "\n",
      "                                          featurizer  n_trees  \n",
      "0  <class 'deepchem.featurizers.fingerprints.Circ...       20  \n",
      "0  <class 'deepchem.featurizers.fingerprints.Circ...       20  \n",
      "Saving predictions to <open file '<fdopen>', mode 'w+b' at 0x7fea994b8f60>\n",
      "Saving model performance scores to <open file '<fdopen>', mode 'w+b' at 0x7fea994b8b70>\n",
      "Saving predictions to <open file '<fdopen>', mode 'w+b' at 0x7fea97ca6e40>\n",
      "Saving model performance scores to <open file '<fdopen>', mode 'w+b' at 0x7fea97ca6f60>\n",
      "  task_name  r2_score  rms_error       split  \\\n",
      "0     label  0.865292   0.846439       train   \n",
      "0     label  0.251678   1.288562  validation   \n",
      "\n",
      "                                          featurizer  n_trees  \n",
      "0  <class 'deepchem.featurizers.fingerprints.Circ...       40  \n",
      "0  <class 'deepchem.featurizers.fingerprints.Circ...       40  \n",
      "Saving predictions to <open file '<fdopen>', mode 'w+b' at 0x7fea994b8810>\n",
      "Saving model performance scores to <open file '<fdopen>', mode 'w+b' at 0x7fea994b8f60>\n",
      "Saving predictions to <open file '<fdopen>', mode 'w+b' at 0x7fea994b8b70>\n",
      "Saving model performance scores to <open file '<fdopen>', mode 'w+b' at 0x7fea97ca6e40>\n",
      "  task_name  r2_score  rms_error       split  \\\n",
      "0     label  0.872805   0.822495       train   \n",
      "0     label  0.279337   1.264525  validation   \n",
      "\n",
      "                                          featurizer  n_trees  \n",
      "0  <class 'deepchem.featurizers.fingerprints.Circ...       80  \n",
      "0  <class 'deepchem.featurizers.fingerprints.Circ...       80  \n",
      "Saving predictions to <open file '<fdopen>', mode 'w+b' at 0x7fea97ca6f60>\n",
      "Saving model performance scores to <open file '<fdopen>', mode 'w+b' at 0x7fea994b8810>\n",
      "Saving predictions to <open file '<fdopen>', mode 'w+b' at 0x7fea994b8f60>\n",
      "Saving model performance scores to <open file '<fdopen>', mode 'w+b' at 0x7fea994b8b70>\n",
      "  task_name  r2_score  rms_error       split  \\\n",
      "0     label  0.871897   0.825426       train   \n",
      "0     label  0.278349   1.265391  validation   \n",
      "\n",
      "                                          featurizer  n_trees  \n",
      "0  <class 'deepchem.featurizers.fingerprints.Circ...      160  \n",
      "0  <class 'deepchem.featurizers.fingerprints.Circ...      160  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_name</th>\n",
       "      <th>r2_score</th>\n",
       "      <th>rms_error</th>\n",
       "      <th>split</th>\n",
       "      <th>featurizer</th>\n",
       "      <th>n_trees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>label</td>\n",
       "      <td>0.850802</td>\n",
       "      <td>0.890800</td>\n",
       "      <td>train</td>\n",
       "      <td>&lt;class 'deepchem.featurizers.grid_featurizer.G...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>label</td>\n",
       "      <td>0.380784</td>\n",
       "      <td>1.172148</td>\n",
       "      <td>validation</td>\n",
       "      <td>&lt;class 'deepchem.featurizers.grid_featurizer.G...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>label</td>\n",
       "      <td>0.877179</td>\n",
       "      <td>0.808230</td>\n",
       "      <td>train</td>\n",
       "      <td>&lt;class 'deepchem.featurizers.grid_featurizer.G...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>label</td>\n",
       "      <td>0.157616</td>\n",
       "      <td>1.367150</td>\n",
       "      <td>validation</td>\n",
       "      <td>&lt;class 'deepchem.featurizers.grid_featurizer.G...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>label</td>\n",
       "      <td>0.900207</td>\n",
       "      <td>0.728532</td>\n",
       "      <td>train</td>\n",
       "      <td>&lt;class 'deepchem.featurizers.grid_featurizer.G...</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>label</td>\n",
       "      <td>0.279117</td>\n",
       "      <td>1.264717</td>\n",
       "      <td>validation</td>\n",
       "      <td>&lt;class 'deepchem.featurizers.grid_featurizer.G...</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>label</td>\n",
       "      <td>0.895135</td>\n",
       "      <td>0.746817</td>\n",
       "      <td>train</td>\n",
       "      <td>&lt;class 'deepchem.featurizers.grid_featurizer.G...</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>label</td>\n",
       "      <td>0.303473</td>\n",
       "      <td>1.243169</td>\n",
       "      <td>validation</td>\n",
       "      <td>&lt;class 'deepchem.featurizers.grid_featurizer.G...</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>label</td>\n",
       "      <td>0.904690</td>\n",
       "      <td>0.711980</td>\n",
       "      <td>train</td>\n",
       "      <td>&lt;class 'deepchem.featurizers.grid_featurizer.G...</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>label</td>\n",
       "      <td>0.275001</td>\n",
       "      <td>1.268323</td>\n",
       "      <td>validation</td>\n",
       "      <td>&lt;class 'deepchem.featurizers.grid_featurizer.G...</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>label</td>\n",
       "      <td>0.818402</td>\n",
       "      <td>0.982774</td>\n",
       "      <td>train</td>\n",
       "      <td>&lt;class 'deepchem.featurizers.fingerprints.Circ...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>label</td>\n",
       "      <td>0.045733</td>\n",
       "      <td>1.455111</td>\n",
       "      <td>validation</td>\n",
       "      <td>&lt;class 'deepchem.featurizers.fingerprints.Circ...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>label</td>\n",
       "      <td>0.837979</td>\n",
       "      <td>0.928291</td>\n",
       "      <td>train</td>\n",
       "      <td>&lt;class 'deepchem.featurizers.fingerprints.Circ...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>label</td>\n",
       "      <td>0.257332</td>\n",
       "      <td>1.283685</td>\n",
       "      <td>validation</td>\n",
       "      <td>&lt;class 'deepchem.featurizers.fingerprints.Circ...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>label</td>\n",
       "      <td>0.865292</td>\n",
       "      <td>0.846439</td>\n",
       "      <td>train</td>\n",
       "      <td>&lt;class 'deepchem.featurizers.fingerprints.Circ...</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>label</td>\n",
       "      <td>0.251678</td>\n",
       "      <td>1.288562</td>\n",
       "      <td>validation</td>\n",
       "      <td>&lt;class 'deepchem.featurizers.fingerprints.Circ...</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>label</td>\n",
       "      <td>0.872805</td>\n",
       "      <td>0.822495</td>\n",
       "      <td>train</td>\n",
       "      <td>&lt;class 'deepchem.featurizers.fingerprints.Circ...</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>label</td>\n",
       "      <td>0.279337</td>\n",
       "      <td>1.264525</td>\n",
       "      <td>validation</td>\n",
       "      <td>&lt;class 'deepchem.featurizers.fingerprints.Circ...</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>label</td>\n",
       "      <td>0.871897</td>\n",
       "      <td>0.825426</td>\n",
       "      <td>train</td>\n",
       "      <td>&lt;class 'deepchem.featurizers.fingerprints.Circ...</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>label</td>\n",
       "      <td>0.278349</td>\n",
       "      <td>1.265391</td>\n",
       "      <td>validation</td>\n",
       "      <td>&lt;class 'deepchem.featurizers.fingerprints.Circ...</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  task_name  r2_score  rms_error       split  \\\n",
       "0     label  0.850802   0.890800       train   \n",
       "0     label  0.380784   1.172148  validation   \n",
       "0     label  0.877179   0.808230       train   \n",
       "0     label  0.157616   1.367150  validation   \n",
       "0     label  0.900207   0.728532       train   \n",
       "0     label  0.279117   1.264717  validation   \n",
       "0     label  0.895135   0.746817       train   \n",
       "0     label  0.303473   1.243169  validation   \n",
       "0     label  0.904690   0.711980       train   \n",
       "0     label  0.275001   1.268323  validation   \n",
       "0     label  0.818402   0.982774       train   \n",
       "0     label  0.045733   1.455111  validation   \n",
       "0     label  0.837979   0.928291       train   \n",
       "0     label  0.257332   1.283685  validation   \n",
       "0     label  0.865292   0.846439       train   \n",
       "0     label  0.251678   1.288562  validation   \n",
       "0     label  0.872805   0.822495       train   \n",
       "0     label  0.279337   1.264525  validation   \n",
       "0     label  0.871897   0.825426       train   \n",
       "0     label  0.278349   1.265391  validation   \n",
       "\n",
       "                                          featurizer  n_trees  \n",
       "0  <class 'deepchem.featurizers.grid_featurizer.G...       10  \n",
       "0  <class 'deepchem.featurizers.grid_featurizer.G...       10  \n",
       "0  <class 'deepchem.featurizers.grid_featurizer.G...       20  \n",
       "0  <class 'deepchem.featurizers.grid_featurizer.G...       20  \n",
       "0  <class 'deepchem.featurizers.grid_featurizer.G...       40  \n",
       "0  <class 'deepchem.featurizers.grid_featurizer.G...       40  \n",
       "0  <class 'deepchem.featurizers.grid_featurizer.G...       80  \n",
       "0  <class 'deepchem.featurizers.grid_featurizer.G...       80  \n",
       "0  <class 'deepchem.featurizers.grid_featurizer.G...      160  \n",
       "0  <class 'deepchem.featurizers.grid_featurizer.G...      160  \n",
       "0  <class 'deepchem.featurizers.fingerprints.Circ...       10  \n",
       "0  <class 'deepchem.featurizers.fingerprints.Circ...       10  \n",
       "0  <class 'deepchem.featurizers.fingerprints.Circ...       20  \n",
       "0  <class 'deepchem.featurizers.fingerprints.Circ...       20  \n",
       "0  <class 'deepchem.featurizers.fingerprints.Circ...       40  \n",
       "0  <class 'deepchem.featurizers.fingerprints.Circ...       40  \n",
       "0  <class 'deepchem.featurizers.fingerprints.Circ...       80  \n",
       "0  <class 'deepchem.featurizers.fingerprints.Circ...       80  \n",
       "0  <class 'deepchem.featurizers.fingerprints.Circ...      160  \n",
       "0  <class 'deepchem.featurizers.fingerprints.Circ...      160  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir, validation_dir, test_dir = tempfile.mkdtemp(), tempfile.mkdtemp(), tempfile.mkdtemp()\n",
    "splittype=\"random\"\n",
    "train_samples, validation_samples, test_samples = featurized_samples.train_valid_test_split(\n",
    "    splittype, train_dir, validation_dir, test_dir, seed=2016)\n",
    "\n",
    "task_types = {\"label\": \"regression\"}\n",
    "performance = pd.DataFrame()\n",
    "import deepchem.models.standard\n",
    "from deepchem.models.standard import SklearnModel\n",
    "from deepchem.utils.dataset import Dataset\n",
    "from deepchem.utils.evaluate import Evaluator\n",
    "\n",
    "n_trees_vals = [10, 20, 40, 80, 160]\n",
    "for feature_type in (complex_featurizers + compound_featurizers):\n",
    "    train_dataset = Dataset(data_dir=train_dir, samples=train_samples, \n",
    "                        featurizers=[feature_type], tasks=[\"label\"])\n",
    "    validation_dataset = Dataset(data_dir=validation_dir, samples=validation_samples, \n",
    "                       featurizers=[feature_type], tasks=[\"label\"])\n",
    "\n",
    "    input_transforms = [\"normalize\", \"truncate\"]\n",
    "    output_transforms = [\"normalize\"]\n",
    "    train_dataset.transform(input_transforms, output_transforms)\n",
    "    validation_dataset.transform(input_transforms, output_transforms)\n",
    "    \n",
    "    for n_trees in n_trees_vals:\n",
    "        model_params = {\"data_shape\": train_dataset.get_data_shape()}\n",
    "\n",
    "        model = SklearnModel(task_types, model_params, model_instance=RandomForestRegressor(n_estimators=n_trees))\n",
    "        model.fit(train_dataset)\n",
    "        model_dir = tempfile.mkdtemp()\n",
    "        model.save(model_dir)\n",
    "\n",
    "\n",
    "        evaluator = Evaluator(model, train_dataset, verbose=True)\n",
    "        with tempfile.NamedTemporaryFile() as train_csv_out:\n",
    "          with tempfile.NamedTemporaryFile() as train_stats_out:\n",
    "            _, train_r2score = evaluator.compute_model_performance(\n",
    "                train_csv_out, train_stats_out)\n",
    "\n",
    "        evaluator = Evaluator(model, validation_dataset, verbose=True)\n",
    "        with tempfile.NamedTemporaryFile() as validation_csv_out:\n",
    "          with tempfile.NamedTemporaryFile() as validation_stats_out:\n",
    "            _, validation_r2score = evaluator.compute_model_performance(\n",
    "                validation_csv_out, validation_stats_out)\n",
    "\n",
    "        train_valid_performance = pd.concat([train_r2score, validation_r2score])\n",
    "        train_valid_performance[\"split\"] = [\"train\", \"validation\"]\n",
    "        train_valid_performance[\"featurizer\"] = [str(feature_type.__class__), str(feature_type.__class__)]\n",
    "        train_valid_performance[\"n_trees\"] = [n_trees, n_trees]\n",
    "        print(train_valid_performance)\n",
    "        performance = pd.concat([performance, train_valid_performance])\n",
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      r2_score\n",
      "10   0.0457328\n",
      "20    0.257332\n",
      "40    0.251678\n",
      "80    0.279337\n",
      "160   0.278349\n",
      "    ligand fingerprints complex features\n",
      "10            0.0457328         0.380784\n",
      "20             0.257332         0.157616\n",
      "40             0.251678         0.279117\n",
      "80             0.279337         0.303473\n",
      "160            0.278349         0.275001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7fea5ec33fd0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fea97e9c210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEPCAYAAABoekJnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fea71d082d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.DataFrame(performance[['r2_score','split','featurizer']].values, index=performance['n_trees'].values, columns=['r2_score', 'split', 'featurizer'])\n",
    "df = df.loc[df['split']==\"validation\"]\n",
    "df = df.drop('split', 1)\n",
    "fingerprint_df = df[df['featurizer'].str.contains('fingerprint')].drop('featurizer', 1)\n",
    "print fingerprint_df\n",
    "fingerprint_df.columns = ['ligand fingerprints']\n",
    "grid_df = df[df['featurizer'].str.contains('grid')].drop('featurizer', 1)\n",
    "grid_df.columns = ['complex features']\n",
    "df = pd.concat([fingerprint_df, grid_df], axis=1)\n",
    "print(df)\n",
    "\n",
    "plt.clf()\n",
    "df.plot()\n",
    "plt.ylabel(\"$R^2$\")\n",
    "plt.xlabel(\"Number of trees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving predictions to <open file '<fdopen>', mode 'w+b' at 0x7fea72843d20>\n",
      "Saving model performance scores to <open file '<fdopen>', mode 'w+b' at 0x7feacef65300>\n",
      "Saving predictions to <open file '<fdopen>', mode 'w+b' at 0x7fea79578270>\n",
      "Saving model performance scores to <open file '<fdopen>', mode 'w+b' at 0x7fea994b8810>\n",
      "  task_name  r2_score  rms_error  split     featurizer  n_trees\n",
      "0     label  0.862417   0.855422  train  <type 'list'>      160\n",
      "0     label  0.381613   1.323630   test  <type 'list'>      160\n"
     ]
    }
   ],
   "source": [
    "train_dir, validation_dir, test_dir = tempfile.mkdtemp(), tempfile.mkdtemp(), tempfile.mkdtemp()\n",
    "splittype=\"random\"\n",
    "train_samples, validation_samples, test_samples = featurized_samples.train_valid_test_split(\n",
    "    splittype, train_dir, validation_dir, test_dir, seed=2016)\n",
    "\n",
    "feature_type = complex_featurizers\n",
    "train_dataset = Dataset(data_dir=train_dir, samples=train_samples, \n",
    "                    featurizers=feature_type, tasks=[\"label\"])\n",
    "validation_dataset = Dataset(data_dir=validation_dir, samples=validation_samples, \n",
    "                   featurizers=feature_type, tasks=[\"label\"])\n",
    "test_dataset = Dataset(data_dir=test_dir, samples=test_samples, \n",
    "                   featurizers=feature_type, tasks=[\"label\"])\n",
    "\n",
    "input_transforms = [\"normalize\", \"truncate\"]\n",
    "output_transforms = [\"normalize\"]\n",
    "train_dataset.transform(input_transforms, output_transforms)\n",
    "validation_dataset.transform(input_transforms, output_transforms)\n",
    "test_dataset.transform(input_transforms, output_transforms)\n",
    "\n",
    "model_params = {\"data_shape\": train_dataset.get_data_shape()}\n",
    "\n",
    "rf_model = SklearnModel(task_types, model_params, model_instance=RandomForestRegressor(n_estimators=20))\n",
    "rf_model.fit(train_dataset)\n",
    "model_dir = tempfile.mkdtemp()\n",
    "rf_model.save(model_dir)\n",
    "\n",
    "\n",
    "evaluator = Evaluator(rf_model, train_dataset, verbose=True)\n",
    "with tempfile.NamedTemporaryFile() as train_csv_out:\n",
    "  with tempfile.NamedTemporaryFile() as train_stats_out:\n",
    "    _, train_r2score = evaluator.compute_model_performance(\n",
    "        train_csv_out, train_stats_out)\n",
    "\n",
    "evaluator = Evaluator(rf_model, test_dataset, verbose=True)\n",
    "test_csv_out = tempfile.NamedTemporaryFile()\n",
    "with tempfile.NamedTemporaryFile() as test_stats_out:\n",
    "    predictions, test_r2score = evaluator.compute_model_performance(\n",
    "        test_csv_out, test_stats_out)\n",
    "\n",
    "train_test_performance = pd.concat([train_r2score, test_r2score])\n",
    "train_test_performance[\"split\"] = [\"train\", \"test\"]\n",
    "train_test_performance[\"featurizer\"] = [str(feature_type.__class__), str(feature_type.__class__)]\n",
    "train_test_performance[\"n_trees\"] = [n_trees, n_trees]\n",
    "print(train_test_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing (0.0018171038259935624, 0.0049446750959222293, 10, 5, False, 0.05, 2, 'glorot_uniform', True)\n",
      "Combo 0/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.001817, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.052310\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 10, 5, False, 0.05, 2, 'glorot_uniform', True)\n",
      "best_validation_score so-far: 0.052310\n",
      "Testing (0.0018171038259935624, 0.0049446750959222293, 10, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "Combo 1/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.001817, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.236239\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 10, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.236239\n",
      "Testing (0.0018171038259935624, 0.0049446750959222293, 10, 5, False, 0.1, 2, 'glorot_uniform', True)\n",
      "Combo 2/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.001817, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.032232\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 10, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.236239\n",
      "Testing (0.0018171038259935624, 0.0049446750959222293, 10, 5, False, 0.1, 2, 'glorot_uniform', False)\n",
      "Combo 3/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.001817, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.124017\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 10, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.236239\n",
      "Testing (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', True)\n",
      "Combo 4/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.001817, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.043953\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 10, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.236239\n",
      "Testing (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "Combo 5/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.001817, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.463186\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.1, 2, 'glorot_uniform', True)\n",
      "Combo 6/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.001817, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.034678\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.1, 2, 'glorot_uniform', False)\n",
      "Combo 7/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.001817, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.148112\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0018171038259935624, 0.0049446750959222293, 1000, 5, False, 0.05, 2, 'glorot_uniform', True)\n",
      "Combo 8/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.001817, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.061816\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0018171038259935624, 0.0049446750959222293, 1000, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "Combo 9/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.001817, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.312484\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0018171038259935624, 0.0049446750959222293, 1000, 5, False, 0.1, 2, 'glorot_uniform', True)\n",
      "Combo 10/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.001817, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.053784\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0018171038259935624, 0.0049446750959222293, 1000, 5, False, 0.1, 2, 'glorot_uniform', False)\n",
      "Combo 11/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.001817, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.230733\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0018171038259935624, 0.0046105219251146717, 10, 5, False, 0.05, 2, 'glorot_uniform', True)\n",
      "Combo 12/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.001817, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.022895\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0018171038259935624, 0.0046105219251146717, 10, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "Combo 13/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.001817, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.029677\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0018171038259935624, 0.0046105219251146717, 10, 5, False, 0.1, 2, 'glorot_uniform', True)\n",
      "Combo 14/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.001817, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.019486\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0018171038259935624, 0.0046105219251146717, 10, 5, False, 0.1, 2, 'glorot_uniform', False)\n",
      "Combo 15/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.001817, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.071316\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0018171038259935624, 0.0046105219251146717, 100, 5, False, 0.05, 2, 'glorot_uniform', True)\n",
      "Combo 16/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.001817, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.045613\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0018171038259935624, 0.0046105219251146717, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "Combo 17/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.001817, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.174035\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0018171038259935624, 0.0046105219251146717, 100, 5, False, 0.1, 2, 'glorot_uniform', True)\n",
      "Combo 18/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.001817, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.040136\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0018171038259935624, 0.0046105219251146717, 100, 5, False, 0.1, 2, 'glorot_uniform', False)\n",
      "Combo 19/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.001817, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.109092\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0018171038259935624, 0.0046105219251146717, 1000, 5, False, 0.05, 2, 'glorot_uniform', True)\n",
      "Combo 20/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.001817, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.064414\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0018171038259935624, 0.0046105219251146717, 1000, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "Combo 21/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.001817, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.255765\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0018171038259935624, 0.0046105219251146717, 1000, 5, False, 0.1, 2, 'glorot_uniform', True)\n",
      "Combo 22/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.001817, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.058625\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0018171038259935624, 0.0046105219251146717, 1000, 5, False, 0.1, 2, 'glorot_uniform', False)\n",
      "Combo 23/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.001817, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.205650\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0018171038259935624, 1.1511283983866343e-06, 10, 5, False, 0.05, 2, 'glorot_uniform', True)\n",
      "Combo 24/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.001817, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.065106\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0018171038259935624, 1.1511283983866343e-06, 10, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "Combo 25/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.001817, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.111463\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0018171038259935624, 1.1511283983866343e-06, 10, 5, False, 0.1, 2, 'glorot_uniform', True)\n",
      "Combo 26/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.001817, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.056052\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0018171038259935624, 1.1511283983866343e-06, 10, 5, False, 0.1, 2, 'glorot_uniform', False)\n",
      "Combo 27/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.001817, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.195030\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0018171038259935624, 1.1511283983866343e-06, 100, 5, False, 0.05, 2, 'glorot_uniform', True)\n",
      "Combo 28/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.001817, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.044930\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0018171038259935624, 1.1511283983866343e-06, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "Combo 29/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.001817, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.069249\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0018171038259935624, 1.1511283983866343e-06, 100, 5, False, 0.1, 2, 'glorot_uniform', True)\n",
      "Combo 30/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.001817, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.037436\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0018171038259935624, 1.1511283983866343e-06, 100, 5, False, 0.1, 2, 'glorot_uniform', False)\n",
      "Combo 31/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.001817, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.341537\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0018171038259935624, 1.1511283983866343e-06, 1000, 5, False, 0.05, 2, 'glorot_uniform', True)\n",
      "Combo 32/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.001817, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.060559\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0018171038259935624, 1.1511283983866343e-06, 1000, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "Combo 33/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.001817, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.229558\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0018171038259935624, 1.1511283983866343e-06, 1000, 5, False, 0.1, 2, 'glorot_uniform', True)\n",
      "Combo 34/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.001817, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.056056\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0018171038259935624, 1.1511283983866343e-06, 1000, 5, False, 0.1, 2, 'glorot_uniform', False)\n",
      "Combo 35/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.001817, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.265421\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0018171038259935624, 2.899543306854146e-06, 10, 5, False, 0.05, 2, 'glorot_uniform', True)\n",
      "Combo 36/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.001817, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.026662\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0018171038259935624, 2.899543306854146e-06, 10, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "Combo 37/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.001817, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.170494\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0018171038259935624, 2.899543306854146e-06, 10, 5, False, 0.1, 2, 'glorot_uniform', True)\n",
      "Combo 38/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.001817, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.056345\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0018171038259935624, 2.899543306854146e-06, 10, 5, False, 0.1, 2, 'glorot_uniform', False)\n",
      "Combo 39/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.001817, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.156114\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0018171038259935624, 2.899543306854146e-06, 100, 5, False, 0.05, 2, 'glorot_uniform', True)\n",
      "Combo 40/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.001817, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.056831\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0018171038259935624, 2.899543306854146e-06, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "Combo 41/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.001817, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.247951\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0018171038259935624, 2.899543306854146e-06, 100, 5, False, 0.1, 2, 'glorot_uniform', True)\n",
      "Combo 42/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.001817, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.037699\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0018171038259935624, 2.899543306854146e-06, 100, 5, False, 0.1, 2, 'glorot_uniform', False)\n",
      "Combo 43/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.001817, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 -0.074958\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0018171038259935624, 2.899543306854146e-06, 1000, 5, False, 0.05, 2, 'glorot_uniform', True)\n",
      "Combo 44/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.001817, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.060160\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0018171038259935624, 2.899543306854146e-06, 1000, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "Combo 45/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.001817, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.121475\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0018171038259935624, 2.899543306854146e-06, 1000, 5, False, 0.1, 2, 'glorot_uniform', True)\n",
      "Combo 46/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.001817, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.058707\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0018171038259935624, 2.899543306854146e-06, 1000, 5, False, 0.1, 2, 'glorot_uniform', False)\n",
      "Combo 47/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.001817, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.240001\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0024041061631945851, 0.0049446750959222293, 10, 5, False, 0.05, 2, 'glorot_uniform', True)\n",
      "Combo 48/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.002404, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.070213\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0024041061631945851, 0.0049446750959222293, 10, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "Combo 49/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.002404, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.160359\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0024041061631945851, 0.0049446750959222293, 10, 5, False, 0.1, 2, 'glorot_uniform', True)\n",
      "Combo 50/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.002404, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.064826\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0024041061631945851, 0.0049446750959222293, 10, 5, False, 0.1, 2, 'glorot_uniform', False)\n",
      "Combo 51/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.002404, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.256100\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0024041061631945851, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', True)\n",
      "Combo 52/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.002404, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.077248\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0024041061631945851, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "Combo 53/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.002404, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.295046\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0024041061631945851, 0.0049446750959222293, 100, 5, False, 0.1, 2, 'glorot_uniform', True)\n",
      "Combo 54/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.002404, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.057201\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0024041061631945851, 0.0049446750959222293, 100, 5, False, 0.1, 2, 'glorot_uniform', False)\n",
      "Combo 55/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.002404, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.292408\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0024041061631945851, 0.0049446750959222293, 1000, 5, False, 0.05, 2, 'glorot_uniform', True)\n",
      "Combo 56/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.002404, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.078842\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0024041061631945851, 0.0049446750959222293, 1000, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "Combo 57/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.002404, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.181136\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0024041061631945851, 0.0049446750959222293, 1000, 5, False, 0.1, 2, 'glorot_uniform', True)\n",
      "Combo 58/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.002404, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.074854\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0024041061631945851, 0.0049446750959222293, 1000, 5, False, 0.1, 2, 'glorot_uniform', False)\n",
      "Combo 59/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.002404, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.104714\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0024041061631945851, 0.0046105219251146717, 10, 5, False, 0.05, 2, 'glorot_uniform', True)\n",
      "Combo 60/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.002404, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.021680\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0024041061631945851, 0.0046105219251146717, 10, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "Combo 61/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.002404, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.224596\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0024041061631945851, 0.0046105219251146717, 10, 5, False, 0.1, 2, 'glorot_uniform', True)\n",
      "Combo 62/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.002404, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.021744\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0024041061631945851, 0.0046105219251146717, 10, 5, False, 0.1, 2, 'glorot_uniform', False)\n",
      "Combo 63/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.002404, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.173444\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0024041061631945851, 0.0046105219251146717, 100, 5, False, 0.05, 2, 'glorot_uniform', True)\n",
      "Combo 64/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.002404, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.053579\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0024041061631945851, 0.0046105219251146717, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "Combo 65/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.002404, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.134248\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0024041061631945851, 0.0046105219251146717, 100, 5, False, 0.1, 2, 'glorot_uniform', True)\n",
      "Combo 66/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.002404, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.054936\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0024041061631945851, 0.0046105219251146717, 100, 5, False, 0.1, 2, 'glorot_uniform', False)\n",
      "Combo 67/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.002404, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.127220\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0024041061631945851, 0.0046105219251146717, 1000, 5, False, 0.05, 2, 'glorot_uniform', True)\n",
      "Combo 68/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.002404, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.078482\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0024041061631945851, 0.0046105219251146717, 1000, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "Combo 69/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.002404, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.210075\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0024041061631945851, 0.0046105219251146717, 1000, 5, False, 0.1, 2, 'glorot_uniform', True)\n",
      "Combo 70/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.002404, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.072222\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0024041061631945851, 0.0046105219251146717, 1000, 5, False, 0.1, 2, 'glorot_uniform', False)\n",
      "Combo 71/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.002404, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.212350\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0024041061631945851, 1.1511283983866343e-06, 10, 5, False, 0.05, 2, 'glorot_uniform', True)\n",
      "Combo 72/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.002404, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.041186\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0024041061631945851, 1.1511283983866343e-06, 10, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "Combo 73/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.002404, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.154450\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0024041061631945851, 1.1511283983866343e-06, 10, 5, False, 0.1, 2, 'glorot_uniform', True)\n",
      "Combo 74/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.002404, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.034845\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0024041061631945851, 1.1511283983866343e-06, 10, 5, False, 0.1, 2, 'glorot_uniform', False)\n",
      "Combo 75/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.002404, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.189899\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0024041061631945851, 1.1511283983866343e-06, 100, 5, False, 0.05, 2, 'glorot_uniform', True)\n",
      "Combo 76/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.002404, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.074428\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0024041061631945851, 1.1511283983866343e-06, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "Combo 77/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.002404, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 -0.006851\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0024041061631945851, 1.1511283983866343e-06, 100, 5, False, 0.1, 2, 'glorot_uniform', True)\n",
      "Combo 78/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.002404, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.051135\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0024041061631945851, 1.1511283983866343e-06, 100, 5, False, 0.1, 2, 'glorot_uniform', False)\n",
      "Combo 79/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.002404, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.049081\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0024041061631945851, 1.1511283983866343e-06, 1000, 5, False, 0.05, 2, 'glorot_uniform', True)\n",
      "Combo 80/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.002404, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.077782\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0024041061631945851, 1.1511283983866343e-06, 1000, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "Combo 81/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.002404, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.196231\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0024041061631945851, 1.1511283983866343e-06, 1000, 5, False, 0.1, 2, 'glorot_uniform', True)\n",
      "Combo 82/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.002404, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.074711\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0024041061631945851, 1.1511283983866343e-06, 1000, 5, False, 0.1, 2, 'glorot_uniform', False)\n",
      "Combo 83/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.002404, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.149155\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0024041061631945851, 2.899543306854146e-06, 10, 5, False, 0.05, 2, 'glorot_uniform', True)\n",
      "Combo 84/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.002404, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.068293\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0024041061631945851, 2.899543306854146e-06, 10, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "Combo 85/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.002404, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.382870\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0024041061631945851, 2.899543306854146e-06, 10, 5, False, 0.1, 2, 'glorot_uniform', True)\n",
      "Combo 86/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.002404, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.063284\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0024041061631945851, 2.899543306854146e-06, 10, 5, False, 0.1, 2, 'glorot_uniform', False)\n",
      "Combo 87/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.002404, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.206639\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0024041061631945851, 2.899543306854146e-06, 100, 5, False, 0.05, 2, 'glorot_uniform', True)\n",
      "Combo 88/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.002404, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.074274\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0024041061631945851, 2.899543306854146e-06, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "Combo 89/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.002404, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 -0.018308\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0024041061631945851, 2.899543306854146e-06, 100, 5, False, 0.1, 2, 'glorot_uniform', True)\n",
      "Combo 90/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.002404, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.043826\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0024041061631945851, 2.899543306854146e-06, 100, 5, False, 0.1, 2, 'glorot_uniform', False)\n",
      "Combo 91/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.002404, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.102377\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0024041061631945851, 2.899543306854146e-06, 1000, 5, False, 0.05, 2, 'glorot_uniform', True)\n",
      "Combo 92/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.002404, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.077323\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0024041061631945851, 2.899543306854146e-06, 1000, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "Combo 93/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.002404, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.157235\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0024041061631945851, 2.899543306854146e-06, 1000, 5, False, 0.1, 2, 'glorot_uniform', True)\n",
      "Combo 94/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.002404, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.075745\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.0024041061631945851, 2.899543306854146e-06, 1000, 5, False, 0.1, 2, 'glorot_uniform', False)\n",
      "Combo 95/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.002404, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.117638\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.087836491715029247, 0.0049446750959222293, 10, 5, False, 0.05, 2, 'glorot_uniform', True)\n",
      "Combo 96/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.087836, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.122820\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.087836491715029247, 0.0049446750959222293, 10, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "Combo 97/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.087836, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.226547\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.087836491715029247, 0.0049446750959222293, 10, 5, False, 0.1, 2, 'glorot_uniform', True)\n",
      "Combo 98/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.087836, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 -0.377501\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.087836491715029247, 0.0049446750959222293, 10, 5, False, 0.1, 2, 'glorot_uniform', False)\n",
      "Combo 99/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.087836, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.038925\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.087836491715029247, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', True)\n",
      "Combo 100/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.087836, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 -0.067861\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.087836491715029247, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "Combo 101/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.087836, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 -0.006282\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.087836491715029247, 0.0049446750959222293, 100, 5, False, 0.1, 2, 'glorot_uniform', True)\n",
      "Combo 102/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.087836, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.049499\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.087836491715029247, 0.0049446750959222293, 100, 5, False, 0.1, 2, 'glorot_uniform', False)\n",
      "Combo 103/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.087836, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 -0.131996\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.087836491715029247, 0.0049446750959222293, 1000, 5, False, 0.05, 2, 'glorot_uniform', True)\n",
      "Combo 104/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.087836, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.096081\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.087836491715029247, 0.0049446750959222293, 1000, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "Combo 105/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.087836, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 nan\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.087836491715029247, 0.0049446750959222293, 1000, 5, False, 0.1, 2, 'glorot_uniform', True)\n",
      "Combo 106/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.087836, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.150608\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.087836491715029247, 0.0049446750959222293, 1000, 5, False, 0.1, 2, 'glorot_uniform', False)\n",
      "Combo 107/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.087836, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 nan\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.087836491715029247, 0.0046105219251146717, 10, 5, False, 0.05, 2, 'glorot_uniform', True)\n",
      "Combo 108/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.087836, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.110046\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.087836491715029247, 0.0046105219251146717, 10, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "Combo 109/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.087836, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 -0.017482\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.087836491715029247, 0.0046105219251146717, 10, 5, False, 0.1, 2, 'glorot_uniform', True)\n",
      "Combo 110/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.087836, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.004933\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.087836491715029247, 0.0046105219251146717, 10, 5, False, 0.1, 2, 'glorot_uniform', False)\n",
      "Combo 111/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.087836, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 -0.007658\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.087836491715029247, 0.0046105219251146717, 100, 5, False, 0.05, 2, 'glorot_uniform', True)\n",
      "Combo 112/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.087836, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 -0.068468\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.087836491715029247, 0.0046105219251146717, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "Combo 113/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.087836, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 nan\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.087836491715029247, 0.0046105219251146717, 100, 5, False, 0.1, 2, 'glorot_uniform', True)\n",
      "Combo 114/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.087836, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.132118\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.087836491715029247, 0.0046105219251146717, 100, 5, False, 0.1, 2, 'glorot_uniform', False)\n",
      "Combo 115/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.087836, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 -0.003936\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.087836491715029247, 0.0046105219251146717, 1000, 5, False, 0.05, 2, 'glorot_uniform', True)\n",
      "Combo 116/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.087836, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.209971\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.087836491715029247, 0.0046105219251146717, 1000, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "Combo 117/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.087836, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 nan\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.087836491715029247, 0.0046105219251146717, 1000, 5, False, 0.1, 2, 'glorot_uniform', True)\n",
      "Combo 118/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.087836, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.092970\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.087836491715029247, 0.0046105219251146717, 1000, 5, False, 0.1, 2, 'glorot_uniform', False)\n",
      "Combo 119/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.087836, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 nan\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.087836491715029247, 1.1511283983866343e-06, 10, 5, False, 0.05, 2, 'glorot_uniform', True)\n",
      "Combo 120/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.087836, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.087274\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.087836491715029247, 1.1511283983866343e-06, 10, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "Combo 121/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.087836, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.059660\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.087836491715029247, 1.1511283983866343e-06, 10, 5, False, 0.1, 2, 'glorot_uniform', True)\n",
      "Combo 122/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.087836, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.064765\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.087836491715029247, 1.1511283983866343e-06, 10, 5, False, 0.1, 2, 'glorot_uniform', False)\n",
      "Combo 123/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.087836, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.139451\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.087836491715029247, 1.1511283983866343e-06, 100, 5, False, 0.05, 2, 'glorot_uniform', True)\n",
      "Combo 124/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.087836, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.255557\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.087836491715029247, 1.1511283983866343e-06, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "Combo 125/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.087836, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 -0.331071\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.087836491715029247, 1.1511283983866343e-06, 100, 5, False, 0.1, 2, 'glorot_uniform', True)\n",
      "Combo 126/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.087836, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.177373\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.087836491715029247, 1.1511283983866343e-06, 100, 5, False, 0.1, 2, 'glorot_uniform', False)\n",
      "Combo 127/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.087836, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 nan\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.087836491715029247, 1.1511283983866343e-06, 1000, 5, False, 0.05, 2, 'glorot_uniform', True)\n",
      "Combo 128/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.087836, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.097581\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.087836491715029247, 1.1511283983866343e-06, 1000, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "Combo 129/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.087836, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 nan\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.087836491715029247, 1.1511283983866343e-06, 1000, 5, False, 0.1, 2, 'glorot_uniform', True)\n",
      "Combo 130/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.087836, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 -0.016843\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.087836491715029247, 1.1511283983866343e-06, 1000, 5, False, 0.1, 2, 'glorot_uniform', False)\n",
      "Combo 131/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.087836, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 nan\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.087836491715029247, 2.899543306854146e-06, 10, 5, False, 0.05, 2, 'glorot_uniform', True)\n",
      "Combo 132/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.087836, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.158728\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.087836491715029247, 2.899543306854146e-06, 10, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "Combo 133/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.087836, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 -0.014144\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.087836491715029247, 2.899543306854146e-06, 10, 5, False, 0.1, 2, 'glorot_uniform', True)\n",
      "Combo 134/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.087836, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 -0.007749\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.087836491715029247, 2.899543306854146e-06, 10, 5, False, 0.1, 2, 'glorot_uniform', False)\n",
      "Combo 135/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.087836, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 -0.006227\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.087836491715029247, 2.899543306854146e-06, 100, 5, False, 0.05, 2, 'glorot_uniform', True)\n",
      "Combo 136/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.087836, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 -0.000649\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.087836491715029247, 2.899543306854146e-06, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "Combo 137/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.087836, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.154036\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.087836491715029247, 2.899543306854146e-06, 100, 5, False, 0.1, 2, 'glorot_uniform', True)\n",
      "Combo 138/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.087836, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.156509\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.087836491715029247, 2.899543306854146e-06, 100, 5, False, 0.1, 2, 'glorot_uniform', False)\n",
      "Combo 139/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.087836, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 -0.073605\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.087836491715029247, 2.899543306854146e-06, 1000, 5, False, 0.05, 2, 'glorot_uniform', True)\n",
      "Combo 140/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.087836, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.064138\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.087836491715029247, 2.899543306854146e-06, 1000, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "Combo 141/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.087836, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 nan\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.087836491715029247, 2.899543306854146e-06, 1000, 5, False, 0.1, 2, 'glorot_uniform', True)\n",
      "Combo 142/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.087836, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.042885\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.087836491715029247, 2.899543306854146e-06, 1000, 5, False, 0.1, 2, 'glorot_uniform', False)\n",
      "Combo 143/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.087836, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 nan\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.088157860097194923, 0.0049446750959222293, 10, 5, False, 0.05, 2, 'glorot_uniform', True)\n",
      "Combo 144/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.088158, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.165792\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.088157860097194923, 0.0049446750959222293, 10, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "Combo 145/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.088158, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.070515\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.088157860097194923, 0.0049446750959222293, 10, 5, False, 0.1, 2, 'glorot_uniform', True)\n",
      "Combo 146/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.088158, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.159047\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.088157860097194923, 0.0049446750959222293, 10, 5, False, 0.1, 2, 'glorot_uniform', False)\n",
      "Combo 147/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.088158, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.177436\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.088157860097194923, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', True)\n",
      "Combo 148/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.088158, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 -0.072050\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.088157860097194923, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "Combo 149/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.088158, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 -0.178082\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.088157860097194923, 0.0049446750959222293, 100, 5, False, 0.1, 2, 'glorot_uniform', True)\n",
      "Combo 150/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.088158, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.161901\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.088157860097194923, 0.0049446750959222293, 100, 5, False, 0.1, 2, 'glorot_uniform', False)\n",
      "Combo 151/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.088158, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 -0.543556\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.088157860097194923, 0.0049446750959222293, 1000, 5, False, 0.05, 2, 'glorot_uniform', True)\n",
      "Combo 152/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.088158, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.191796\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.088157860097194923, 0.0049446750959222293, 1000, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "Combo 153/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.088158, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 nan\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.088157860097194923, 0.0049446750959222293, 1000, 5, False, 0.1, 2, 'glorot_uniform', True)\n",
      "Combo 154/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.088158, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.239052\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.088157860097194923, 0.0049446750959222293, 1000, 5, False, 0.1, 2, 'glorot_uniform', False)\n",
      "Combo 155/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.088158, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 nan\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.088157860097194923, 0.0046105219251146717, 10, 5, False, 0.05, 2, 'glorot_uniform', True)\n",
      "Combo 156/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.088158, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 -0.267473\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.088157860097194923, 0.0046105219251146717, 10, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "Combo 157/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.088158, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.224696\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.088157860097194923, 0.0046105219251146717, 10, 5, False, 0.1, 2, 'glorot_uniform', True)\n",
      "Combo 158/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.088158, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.134377\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.088157860097194923, 0.0046105219251146717, 10, 5, False, 0.1, 2, 'glorot_uniform', False)\n",
      "Combo 159/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.088158, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 -0.160847\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.088157860097194923, 0.0046105219251146717, 100, 5, False, 0.05, 2, 'glorot_uniform', True)\n",
      "Combo 160/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.088158, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 -0.173279\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.088157860097194923, 0.0046105219251146717, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "Combo 161/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.088158, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 -0.069503\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.088157860097194923, 0.0046105219251146717, 100, 5, False, 0.1, 2, 'glorot_uniform', True)\n",
      "Combo 162/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.088158, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.265625\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.088157860097194923, 0.0046105219251146717, 100, 5, False, 0.1, 2, 'glorot_uniform', False)\n",
      "Combo 163/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.088158, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 -0.097968\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.088157860097194923, 0.0046105219251146717, 1000, 5, False, 0.05, 2, 'glorot_uniform', True)\n",
      "Combo 164/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.088158, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.144767\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.088157860097194923, 0.0046105219251146717, 1000, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "Combo 165/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.088158, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 nan\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.088157860097194923, 0.0046105219251146717, 1000, 5, False, 0.1, 2, 'glorot_uniform', True)\n",
      "Combo 166/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.088158, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.262830\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.088157860097194923, 0.0046105219251146717, 1000, 5, False, 0.1, 2, 'glorot_uniform', False)\n",
      "Combo 167/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.088158, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 nan\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.088157860097194923, 1.1511283983866343e-06, 10, 5, False, 0.05, 2, 'glorot_uniform', True)\n",
      "Combo 168/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.088158, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.121178\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.088157860097194923, 1.1511283983866343e-06, 10, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "Combo 169/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.088158, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.191104\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.088157860097194923, 1.1511283983866343e-06, 10, 5, False, 0.1, 2, 'glorot_uniform', True)\n",
      "Combo 170/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.088158, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.103315\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.088157860097194923, 1.1511283983866343e-06, 10, 5, False, 0.1, 2, 'glorot_uniform', False)\n",
      "Combo 171/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.088158, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 -0.009138\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.088157860097194923, 1.1511283983866343e-06, 100, 5, False, 0.05, 2, 'glorot_uniform', True)\n",
      "Combo 172/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.088158, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.050506\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.088157860097194923, 1.1511283983866343e-06, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "Combo 173/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.088158, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 nan\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.088157860097194923, 1.1511283983866343e-06, 100, 5, False, 0.1, 2, 'glorot_uniform', True)\n",
      "Combo 174/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.088158, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 -0.148493\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.088157860097194923, 1.1511283983866343e-06, 100, 5, False, 0.1, 2, 'glorot_uniform', False)\n",
      "Combo 175/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.088158, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 -0.006741\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.088157860097194923, 1.1511283983866343e-06, 1000, 5, False, 0.05, 2, 'glorot_uniform', True)\n",
      "Combo 176/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.088158, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.116588\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.088157860097194923, 1.1511283983866343e-06, 1000, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "Combo 177/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.088158, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 nan\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.088157860097194923, 1.1511283983866343e-06, 1000, 5, False, 0.1, 2, 'glorot_uniform', True)\n",
      "Combo 178/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.088158, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.099925\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.088157860097194923, 1.1511283983866343e-06, 1000, 5, False, 0.1, 2, 'glorot_uniform', False)\n",
      "Combo 179/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.088158, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 nan\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.088157860097194923, 2.899543306854146e-06, 10, 5, False, 0.05, 2, 'glorot_uniform', True)\n",
      "Combo 180/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.088158, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 -0.118604\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.088157860097194923, 2.899543306854146e-06, 10, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "Combo 181/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.088158, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.045078\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.088157860097194923, 2.899543306854146e-06, 10, 5, False, 0.1, 2, 'glorot_uniform', True)\n",
      "Combo 182/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.088158, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.057166\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.088157860097194923, 2.899543306854146e-06, 10, 5, False, 0.1, 2, 'glorot_uniform', False)\n",
      "Combo 183/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.088158, nb_hidden 10, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 0.001017\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.088157860097194923, 2.899543306854146e-06, 100, 5, False, 0.05, 2, 'glorot_uniform', True)\n",
      "Combo 184/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.088158, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.176240\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.088157860097194923, 2.899543306854146e-06, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "Combo 185/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.088158, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.000722\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.088157860097194923, 2.899543306854146e-06, 100, 5, False, 0.1, 2, 'glorot_uniform', True)\n",
      "Combo 186/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.088158, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 -0.003826\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.088157860097194923, 2.899543306854146e-06, 100, 5, False, 0.1, 2, 'glorot_uniform', False)\n",
      "Combo 187/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.088158, nb_hidden 100, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 -7744071744746713088.000000\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.088157860097194923, 2.899543306854146e-06, 1000, 5, False, 0.05, 2, 'glorot_uniform', True)\n",
      "Combo 188/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.088158, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 0.088296\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.088157860097194923, 2.899543306854146e-06, 1000, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "Combo 189/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.088158, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.050000 => Validation set R^2 nan\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.088157860097194923, 2.899543306854146e-06, 1000, 5, False, 0.1, 2, 'glorot_uniform', True)\n",
      "Combo 190/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.088158, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 -0.030295\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Testing (0.088157860097194923, 2.899543306854146e-06, 1000, 5, False, 0.1, 2, 'glorot_uniform', False)\n",
      "Combo 191/192\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "learning_rate 0.088158, nb_hidden 1000, nb_epoch 5, nesterov False, dropout 0.100000 => Validation set R^2 nan\n",
      "Best hyperparameters so-far: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score so-far: 0.463186\n",
      "Best hyperparameters: (0.0018171038259935624, 0.0049446750959222293, 100, 5, False, 0.05, 2, 'glorot_uniform', False)\n",
      "best_validation_score: 0.463186\n"
     ]
    }
   ],
   "source": [
    "import deepchem.models.deep\n",
    "reload(deepchem.models.deep)\n",
    "from deepchem.models.deep import SingleTaskDNN\n",
    "import numpy.random\n",
    "from operator import mul\n",
    "import itertools\n",
    "\n",
    "model_params = {\"activation\": \"relu\",\n",
    "                \"momentum\": .9,\n",
    "                \"batch_size\": 64,\n",
    "                \"nb_epoch\": 30,\n",
    "                \"data_shape\": train_dataset.get_data_shape()}\n",
    "\n",
    "lr_list = np.power(10., np.random.uniform(-3, -1, size=4))\n",
    "decay_list = np.power(10., np.random.uniform(-6, -2, size=4))\n",
    "nb_hidden_list = [10, 100, 1000]\n",
    "nb_epoch_list = [5]\n",
    "nesterov_list = [False]\n",
    "dropout_list = [0.05, .1]\n",
    "nb_layers_list = [2]\n",
    "init_list = [\"glorot_uniform\"]\n",
    "batchnorm_list = [True, False]\n",
    "hyperparameters = [lr_list, decay_list, nb_hidden_list, nb_epoch_list,\n",
    "                   nesterov_list, dropout_list, nb_layers_list,\n",
    "                   init_list, batchnorm_list]\n",
    "num_combinations = reduce(mul, [len(l) for l in hyperparameters])\n",
    "best_validation_score = -np.inf\n",
    "best_hyperparams = None\n",
    "best_model, best_model_dir = None, None\n",
    "performance_df = pd.DataFrame()\n",
    "for ind, hyperparameter_tuple in enumerate(itertools.product(*hyperparameters)):\n",
    "    print(\"Testing %s\" % str(hyperparameter_tuple))\n",
    "    print(\"Combo %d/%d\" % (ind, num_combinations))\n",
    "    (lr, decay, nb_hidden, nb_epoch, nesterov, dropout,\n",
    "     nb_layers, init, batchnorm) = hyperparameter_tuple\n",
    "    model_params[\"nb_hidden\"] = nb_hidden\n",
    "    model_params[\"decay\"] = decay\n",
    "    model_params[\"learning_rate\"] = lr\n",
    "    model_params[\"nb_epoch\"] = nb_epoch\n",
    "    model_params[\"nesterov\"] = nesterov\n",
    "    model_params[\"dropout\"] = dropout\n",
    "    model_params[\"nb_layers\"] = nb_layers\n",
    "    model_params[\"init\"] = init\n",
    "    model_params[\"batchnorm\"] = batchnorm\n",
    "    model_dir = tempfile.mkdtemp()\n",
    "    model = SingleTaskDNN(task_types, model_params)\n",
    "    model.fit(train_dataset)\n",
    "    model.save(model_dir)\n",
    "    \n",
    "    evaluator = Evaluator(model, validation_dataset)\n",
    "    valid_csv_out = tempfile.NamedTemporaryFile()\n",
    "    valid_stats_out = tempfile.NamedTemporaryFile()\n",
    "    df, r2score = evaluator.compute_model_performance(\n",
    "        valid_csv_out, valid_stats_out)\n",
    "    r2score[\"hyperparameters\"] = str(hyperparameters)\n",
    "    performance_df = pd.concat([performance_df, r2score])\n",
    "    valid_r2_score = r2score.iloc[0][\"r2_score\"]\n",
    "    print(\"learning_rate %f, nb_hidden %d, nb_epoch %d, nesterov %s, dropout %f => Validation set R^2 %f\" %\n",
    "          (lr, nb_hidden, nb_epoch, str(nesterov), dropout, valid_r2_score))\n",
    "    if valid_r2_score > best_validation_score:\n",
    "        best_validation_score = valid_r2_score\n",
    "        best_hyperparams = hyperparameter_tuple\n",
    "        if best_model_dir is not None:\n",
    "            shutil.rmtree(best_model_dir)\n",
    "        best_model_dir = model_dir\n",
    "        best_model = model\n",
    "    else:\n",
    "        shutil.rmtree(model_dir)\n",
    "    print(\"Best hyperparameters so-far: %s\" % str(best_hyperparams))\n",
    "    print(\"best_validation_score so-far: %f\" % best_validation_score)\n",
    "\n",
    "print(\"Best hyperparameters: %s\" % str(best_hyperparams))\n",
    "print(\"best_validation_score: %f\" % best_validation_score)\n",
    "best_dnn = best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ids             3gnwCC1CCCC(C(O)N2C3CCCC(O)C3NC3CC(C)(C)CS(O)(...\n",
      "label                                                     1.31713\n",
      "label_pred                                                1.20469\n",
      "label_weight                                                    1\n",
      "y_means                                                     6.883\n",
      "y_stds                                                     1.6832\n",
      "Name: 155, dtype: object\n",
      "DNN Test set R^2 0.442633\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNN Test set R^2 0.442633\n",
      "RF Test set R^2 0.381613\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEZCAYAAABrUHmEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fea8c990a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEZCAYAAABrUHmEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7feaad2d0f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dnn_test_csv_out = tempfile.NamedTemporaryFile()\n",
    "dnn_test_stats_out = tempfile.NamedTemporaryFile()\n",
    "dnn_test_evaluator = Evaluator(best_dnn, test_dataset)\n",
    "dnn_test_df, dnn_test_r2score = dnn_test_evaluator.compute_model_performance(\n",
    "    dnn_test_csv_out, dnn_test_stats_out)\n",
    "dnn_test_r2_score = dnn_test_r2score.iloc[0][\"r2_score\"]\n",
    "print(\"DNN Test set R^2 %f\" % (dnn_test_r2_score))\n",
    "\n",
    "task = \"label\"\n",
    "dnn_predicted_test = np.array(dnn_test_df[task + \"_pred\"])\n",
    "dnn_true_test = np.array(dnn_test_df[task])\n",
    "\n",
    "plt.clf()\n",
    "plt.scatter(dnn_true_test, dnn_predicted_test)\n",
    "plt.xlabel('Predicted Ki')\n",
    "plt.ylabel('True Ki')\n",
    "plt.title(r'DNN predicted vs. true Ki')\n",
    "plt.xlim([-2, 2])\n",
    "plt.ylim([-2, 2])\n",
    "plt.plot([-3, 3], [-3, 3], marker=\".\", color='k')\n",
    "\n",
    "rf_test_csv_out = tempfile.NamedTemporaryFile()\n",
    "rf_test_stats_out = tempfile.NamedTemporaryFile()\n",
    "rf_test_evaluator = Evaluator(rf_model, test_dataset)\n",
    "rf_test_df, rf_test_r2score = rf_test_evaluator.compute_model_performance(\n",
    "    rf_test_csv_out, rf_test_stats_out)\n",
    "rf_test_r2_score = rf_test_r2score.iloc[0][\"r2_score\"]\n",
    "print(\"RF Test set R^2 %f\" % (rf_test_r2_score))\n",
    "plt.show()\n",
    "\n",
    "task = \"label\"\n",
    "rf_predicted_test = np.array(rf_test_df[task + \"_pred\"])\n",
    "rf_true_test = np.array(rf_test_df[task])\n",
    "plt.scatter(rf_true_test, rf_predicted_test)\n",
    "plt.xlabel('Predicted Ki')\n",
    "plt.ylabel('True Ki')\n",
    "plt.title(r'RF predicted vs. true Ki')\n",
    "plt.xlim([-2, 2])\n",
    "plt.ylim([-2, 2])\n",
    "plt.plot([-3, 3], [-3, 3], marker=\".\", color='k')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = dnn_test_df.sort(['label'], ascending=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_complex = predictions.iloc[0]['ids']\n",
    "best_complex = dataset.loc[dataset['complex_id']==top_complex]\n",
    "\n",
    "protein_mdtraj = convert_lines_to_mdtraj(best_complex[\"protein_pdb\"].values[0])\n",
    "ligand_mdtraj = convert_lines_to_mdtraj(best_complex[\"ligand_pdb\"].values[0])\n",
    "complex_mdtraj = combine_mdtraj(protein_mdtraj, ligand_mdtraj)\n",
    "ngltraj = visualize_complex(complex_mdtraj)\n",
    "ngltraj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_complex = predictions.iloc[1]['ids']\n",
    "best_complex = dataset.loc[dataset['complex_id']==top_complex]\n",
    "\n",
    "protein_mdtraj = convert_lines_to_mdtraj(best_complex[\"protein_pdb\"].values[0])\n",
    "ligand_mdtraj = convert_lines_to_mdtraj(best_complex[\"ligand_pdb\"].values[0])\n",
    "complex_mdtraj = combine_mdtraj(protein_mdtraj, ligand_mdtraj)\n",
    "ngltraj = visualize_complex(complex_mdtraj)\n",
    "ngltraj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_complex = predictions.iloc[predictions.shape[0]-1]['ids']\n",
    "best_complex = dataset.loc[dataset['complex_id']==top_complex]\n",
    "\n",
    "protein_mdtraj = convert_lines_to_mdtraj(best_complex[\"protein_pdb\"].values[0])\n",
    "ligand_mdtraj = convert_lines_to_mdtraj(best_complex[\"ligand_pdb\"].values[0])\n",
    "complex_mdtraj = combine_mdtraj(protein_mdtraj, ligand_mdtraj)\n",
    "ngltraj = visualize_complex(complex_mdtraj)\n",
    "ngltraj"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
