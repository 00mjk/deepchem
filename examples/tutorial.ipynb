{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Written by Evan Feinberg and Bharath Ramsundar\n",
    "\n",
    "Copyright 2016, Stanford University\n",
    "\n",
    "#Welcome to the deepchem tutorial. In this iPython Notebook, one can follow along with the code below to learn how to fit machine learning models with rich predictive power on chemical datasets.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview:\n",
    "\n",
    "In this tutorial, you will trace an arc from loading a raw dataset to fitting a cutting edge ML technique for predicting binding affinities. This will be accomplished by writing simple commands to access the deepchem Python API, encompassing the following broad steps:\n",
    "\n",
    "1. Loading a chemical dataset, consisting of a series of protein-ligand complexes.\n",
    "2. Featurizing each protein-ligand complexes with various featurization schemes. \n",
    "3. Fitting a series of models with these featurized protein-ligand complexes.\n",
    "4. Visualizing the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's point to a \"dataset\" file. This can come in the format of a CSV file or Pandas DataFrame. Regardless\n",
    "of file format, it must be columnar data, where each row is a molecular system, and each column represents\n",
    "a different piece of information about that system. For instance, in this example, every row reflects a \n",
    "protein-ligand complex, and the following columns are present: a unique complex identifier; the SMILES string\n",
    "of the ligand; the binding affinity (Ki) of the ligand to the protein in the complex; a Python `list` of all lines\n",
    "in a PDB file for the protein alone; and a Python `list` of all lines in a ligand file for the ligand alone.\n",
    "\n",
    "This should become clearer with the example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_file= \"../datasets/pdbbind_core_df.pkl.gz\"\n",
    "from deepchem.utils.save import load_from_disk\n",
    "dataset = load_from_disk(dataset_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what `dataset` looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of dataset is: <class 'pandas.core.frame.DataFrame'>\n",
      "  pdb_id                                             smiles  \\\n",
      "0   2d3u        CC1CCCCC1S(O)(O)NC1CC(C2CCC(CN)CC2)SC1C(O)O   \n",
      "1   3cyx  CC(C)(C)NC(O)C1CC2CCCCC2C[NH+]1CC(O)C(CC1CCCCC...   \n",
      "2   3uo4        OC(O)C1CCC(NC2NCCC(NC3CCCCC3C3CCCCC3)N2)CC1   \n",
      "3   1p1q                         CC1ONC(O)C1CC([NH3+])C(O)O   \n",
      "4   3ag9  NC(O)C(CCC[NH2+]C([NH3+])[NH3+])NC(O)C(CCC[NH2...   \n",
      "\n",
      "                                          complex_id  \\\n",
      "0    2d3uCC1CCCCC1S(O)(O)NC1CC(C2CCC(CN)CC2)SC1C(O)O   \n",
      "1  3cyxCC(C)(C)NC(O)C1CC2CCCCC2C[NH+]1CC(O)C(CC1C...   \n",
      "2    3uo4OC(O)C1CCC(NC2NCCC(NC3CCCCC3C3CCCCC3)N2)CC1   \n",
      "3                     1p1qCC1ONC(O)C1CC([NH3+])C(O)O   \n",
      "4  3ag9NC(O)C(CCC[NH2+]C([NH3+])[NH3+])NC(O)C(CCC...   \n",
      "\n",
      "                                         protein_pdb  \\\n",
      "0  [HEADER    2D3U PROTEIN\\n, COMPND    2D3U PROT...   \n",
      "1  [HEADER    3CYX PROTEIN\\n, COMPND    3CYX PROT...   \n",
      "2  [HEADER    3UO4 PROTEIN\\n, COMPND    3UO4 PROT...   \n",
      "3  [HEADER    1P1Q PROTEIN\\n, COMPND    1P1Q PROT...   \n",
      "4  [HEADER    3AG9 PROTEIN\\n, COMPND    3AG9 PROT...   \n",
      "\n",
      "                                          ligand_pdb  \\\n",
      "0  [COMPND    2d3u ligand \\n, AUTHOR    GENERATED...   \n",
      "1  [COMPND    3cyx ligand \\n, AUTHOR    GENERATED...   \n",
      "2  [COMPND    3uo4 ligand \\n, AUTHOR    GENERATED...   \n",
      "3  [COMPND    1p1q ligand \\n, AUTHOR    GENERATED...   \n",
      "4  [COMPND    3ag9 ligand \\n, AUTHOR    GENERATED...   \n",
      "\n",
      "                                         ligand_mol2 label  \n",
      "0  [### \\n, ### Created by X-TOOL on Thu Aug 28 2...  6.92  \n",
      "1  [### \\n, ### Created by X-TOOL on Thu Aug 28 2...  8.00  \n",
      "2  [### \\n, ### Created by X-TOOL on Fri Aug 29 0...  6.52  \n",
      "3  [### \\n, ### Created by X-TOOL on Thu Aug 28 2...  4.89  \n",
      "4  [### \\n, ### Created by X-TOOL on Thu Aug 28 2...  8.05  \n",
      "Shape of dataset is: (193, 7)\n"
     ]
    }
   ],
   "source": [
    "print(\"Type of dataset is: %s\" % str(type(dataset)))\n",
    "print(dataset[:5])\n",
    "print(\"Shape of dataset is: %s\" % str(dataset.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we're oriented, let's use ML to do some chemistry. \n",
    "\n",
    "So, step (2) will entail featurizing the dataset.\n",
    "\n",
    "The available featurizations that come standard with deepchem are ECFP4 fingerprints, RDKit descriptors, NNScore-style bdescriptors, and hybrid binding pocket descriptors. Details can be found on ```deepchem.io```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from deepchem.featurizers.fingerprints import CircularFingerprint\n",
    "from deepchem.featurizers.basic import RDKitDescriptors\n",
    "from deepchem.featurizers.nnscore import NNScoreComplexFeaturizer\n",
    "\n",
    "compound_featurizers = [CircularFingerprint(size=1024)]\n",
    "complex_featurizers = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how we separate our featurizers into those that featurize individual chemical compounds, compound_featurizers, and those that featurize molecular complexes, complex_featurizers.\n",
    "\n",
    "Now, let's perform the actual featurization. Calling ```featurizer.featurize()``` will return an instance of class ```FeaturizedSamples```. Internally, ```featurizer.featurize()``` (a) computes the user-specified features on the data, (b) transforms the inputs into X and y NumPy arrays suitable for ML algorithms, and (c) constructs a ```FeaturizedSamples()``` instance that has useful methods, such as an iterator, over the featurized data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Make a directory in which to store the featurized complexes.\n",
    "import tempfile, shutil\n",
    "feature_dir = tempfile.mkdtemp()\n",
    "samples_dir = tempfile.mkdtemp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from deepchem.featurizers.featurize import DataFeaturizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featurizers = compound_featurizers + complex_featurizers\n",
    "featurizer = DataFeaturizer(tasks=[\"label\"],\n",
    "                            smiles_field=\"smiles\",\n",
    "                            protein_pdb_field=\"protein_pdb\",\n",
    "                            ligand_pdb_field=\"ligand_pdb\",\n",
    "                            compound_featurizers=compound_featurizers,\n",
    "                            complex_featurizers=complex_featurizers,\n",
    "                            id_field=\"complex_id\",\n",
    "                            verbose=False)\n",
    "featurized_samples = featurizer.featurize(dataset_file, feature_dir, samples_dir,\n",
    "                                          shard_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we conduct a train-test split. If you'd like, you can choose `splittype=\"scaffold\"` instead to perform a train-test split based on Bemis-Murcko scaffolds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "splittype = \"random\"\n",
    "train_dir, test_dir = tempfile.mkdtemp(), tempfile.mkdtemp()\n",
    "\n",
    "train_samples, test_samples = featurized_samples.train_test_split(\n",
    "    splittype, train_dir, test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate separate instances of the Dataset() object to hermetically seal the train dataset from the test dataset. This style lends itself easily to validation-set type hyperparameter searches, which we will illustate in a separate tutorial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from deepchem.utils.dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_dataset = Dataset(data_dir=train_dir, samples=train_samples, \n",
    "                        featurizers=featurizers, tasks=[\"label\"])\n",
    "test_dataset = Dataset(data_dir=test_dir, samples=test_samples, \n",
    "                       featurizers=featurizers, tasks=[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of many ML algorithms hinges greatly on careful data preprocessing. Deepchem comes standard with a few options for such preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_transforms = [\"normalize\", \"truncate\"]\n",
    "output_transforms = [\"normalize\"]\n",
    "train_dataset.transform(input_transforms, output_transforms)\n",
    "test_dataset.transform(input_transforms, output_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we're ready to do some learning! To set up a model, we will need: (a) a dictionary ```task_types``` that maps a task, in this case ```label```, i.e. the Ki, to the type of the task, in this case ```regression```. For the multitask use case, one will have a series of keys, each of which is a different task (Ki, solubility, renal half-life, etc.) that maps to a different task type (regression or classification).\n",
    "\n",
    "To fit a deepchem model, first we instantiate one of the provided (or user-written) model classes. In this case, we have a created a convenience class to wrap around any ML model available in Sci-Kit Learn that can in turn be used to interoperate with deepchem. To instantiate an ```SklearnModel```, you will need (a) task_types, (b) model_params, another ```dict``` as illustrated below, and (c) a ```model_instance``` defining the type of model you would like to fit, in this case a ```RandomForestRegressor```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from deepchem.models.standard import SklearnModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "task_types = {\"label\": \"regression\"}\n",
    "model_params = {\"data_shape\": train_dataset.get_data_shape()}\n",
    "\n",
    "model = SklearnModel(task_types, model_params, model_instance=RandomForestRegressor())\n",
    "model.fit(train_dataset)\n",
    "model_dir = tempfile.mkdtemp()\n",
    "model.save(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from deepchem.utils.evaluate import Evaluator\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving predictions to <open file '<fdopen>', mode 'w+b' at 0x7facace9c9c0>\n",
      "Saving model performance scores to <open file '<fdopen>', mode 'w+b' at 0x7facbd542540>\n",
      "Saving predictions to <open file '<fdopen>', mode 'w+b' at 0x7facbd5424b0>\n",
      "Saving model performance scores to <open file '<fdopen>', mode 'w+b' at 0x7facbd542420>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_name</th>\n",
       "      <th>r2_score</th>\n",
       "      <th>rms_error</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>label</td>\n",
       "      <td>0.792865</td>\n",
       "      <td>0.992007</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>label</td>\n",
       "      <td>0.184925</td>\n",
       "      <td>2.240413</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  task_name  r2_score  rms_error  split\n",
       "0     label  0.792865   0.992007  train\n",
       "0     label  0.184925   2.240413   test"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = Evaluator(model, train_dataset, verbose=True)\n",
    "with tempfile.NamedTemporaryFile() as train_csv_out:\n",
    "  with tempfile.NamedTemporaryFile() as train_stats_out:\n",
    "    _, train_r2score = evaluator.compute_model_performance(\n",
    "        train_csv_out, train_stats_out)\n",
    "\n",
    "evaluator = Evaluator(model, test_dataset, verbose=True)\n",
    "with tempfile.NamedTemporaryFile() as test_csv_out:\n",
    "  with tempfile.NamedTemporaryFile() as test_stats_out:\n",
    "    _, test_r2score = evaluator.compute_model_performance(\n",
    "        test_csv_out, test_stats_out)\n",
    "\n",
    "train_test_performance = pd.concat([train_r2score, test_r2score])\n",
    "train_test_performance[\"split\"] = [\"train\", \"test\"]\n",
    "train_test_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#The protein-ligand complex view."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The preceding simple example, in few yet intuitive lines of code, traces the machine learning arc from featurizing a raw dataset to fitting and evaluating a model. \n",
    "\n",
    "In this next section, we illustrate ```deepchem```'s modularity, and thereby the ease with which one can explore different featurization schemes, different models, and combinations thereof, to achieve the best performance on a given dataset. We will demonstrate this by examining protein-ligand interactions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous section, we featurized only the ligand. The signal we observed in R^2 reflects the ability of circular fingerprints and random forests to learn general features that make ligands \"drug-like.\" However, the affinity of a drug for a target is determined not only by the drug itself, of course, but the way in which it interacts with a protein. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TraitError",
     "evalue": "The 'kernel' trait of a Comm instance must be a Kernel, but a value of type 'NoneType' (i.e. None) was specified.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTraitError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-120-758caab6de6d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnglview\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mstruc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnglview\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPdbIdStructure\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;34m\"3pqr\"\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;31m# load file from RCSB PDB\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnglview\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNGLWidget\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mstruc\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;31m# create widget\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mw\u001b[0m \u001b[1;31m# display widget\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/enf/anaconda/lib/python2.7/site-packages/nglview/__init__.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, structure, trajectory, representations, parameters, **kwargs)\u001b[0m\n\u001b[0;32m    253\u001b[0m     def __init__(self, structure, trajectory=None,\n\u001b[0;32m    254\u001b[0m                  representations=None, parameters=None, **kwargs):\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNGLWidget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/enf/anaconda/lib/python2.7/site-packages/ipywidgets/widgets/widget.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *pargs, **kwargs)\u001b[0m\n\u001b[0;32m    503\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mpargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 505\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDOMWidget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mpargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    506\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    507\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_validate_border\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/enf/anaconda/lib/python2.7/site-packages/ipywidgets/widgets/widget.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[0mWidget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_widget_constructed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/enf/anaconda/lib/python2.7/site-packages/ipywidgets/widgets/widget.pyc\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    190\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model_id\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'comm_id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 192\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mComm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_comm_changed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/enf/anaconda/lib/python2.7/site-packages/ipykernel/comm/comm.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, target_name, data, metadata, buffers, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;31m# I am primary, open my peer.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbuffers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_closed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/enf/anaconda/lib/python2.7/site-packages/ipykernel/comm/comm.pyc\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, data, metadata, buffers)\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m         \u001b[0mcomm_manager\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'comm_manager'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcomm_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m             raise RuntimeError(\"Comms cannot be opened without a kernel \"\n",
      "\u001b[1;32m/home/enf/anaconda/lib/python2.7/site-packages/traitlets/traitlets.pyc\u001b[0m in \u001b[0;36m__get__\u001b[1;34m(self, obj, cls)\u001b[0m\n\u001b[0;32m    527\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 529\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/enf/anaconda/lib/python2.7/site-packages/traitlets/traitlets.pyc\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, obj, cls)\u001b[0m\n\u001b[0;32m    506\u001b[0m                 raise TraitError(\"No default value found for %s trait of %r\"\n\u001b[0;32m    507\u001b[0m                                  % (self.name, obj))\n\u001b[1;32m--> 508\u001b[1;33m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdynamic_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    509\u001b[0m             \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_trait_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/enf/anaconda/lib/python2.7/site-packages/traitlets/traitlets.pyc\u001b[0m in \u001b[0;36m_validate\u001b[1;34m(self, obj, value)\u001b[0m\n\u001b[0;32m    562\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'validate'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 564\u001b[1;33m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    565\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cross_validation_lock\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cross_validate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/enf/anaconda/lib/python2.7/site-packages/traitlets/traitlets.pyc\u001b[0m in \u001b[0;36mvalidate\u001b[1;34m(self, obj, value)\u001b[0m\n\u001b[0;32m   1546\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1547\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1548\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1549\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1550\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/enf/anaconda/lib/python2.7/site-packages/traitlets/traitlets.pyc\u001b[0m in \u001b[0;36merror\u001b[1;34m(self, obj, value)\u001b[0m\n\u001b[0;32m   1393\u001b[0m                 \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1395\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mTraitError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1396\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTraitError\u001b[0m: The 'kernel' trait of a Comm instance must be a Kernel, but a value of type 'NoneType' (i.e. None) was specified."
     ]
    }
   ],
   "source": [
    "import nglview\n",
    "reload(nglview)\n",
    "import nglview\n",
    "struc = nglview.PdbIdStructure( \"3pqr\" ) # load file from RCSB PDB\n",
    "w = nglview.NGLWidget( struc ) # create widget\n",
    "w # display widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class fingerprints32(CircularFingerprint):\n",
    "    def __init__(self):\n",
    "        super(fingerprints32, self).__init__(size=32)\n",
    "        \n",
    "class fingerprints64(CircularFingerprint):\n",
    "    def __init__(self):\n",
    "        super(fingerprints64, self).__init__(size=64)\n",
    "        \n",
    "class fingerprints128(CircularFingerprint):\n",
    "    def __init__(self):\n",
    "        super(fingerprints128, self).__init__(size=128)\n",
    "\n",
    "class fingerprints256(CircularFingerprint):\n",
    "    def __init__(self):\n",
    "        super(fingerprints256, self).__init__(size=256)\n",
    "\n",
    "class fingerprints512(CircularFingerprint):\n",
    "    def __init__(self):\n",
    "        super(fingerprints512, self).__init__(size=512)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from imp import reload\n",
    "import deepchem.featurizers.grid_featurizer\n",
    "reload(deepchem.featurizers.grid_featurizer)\n",
    "from deepchem.featurizers.grid_featurizer import GridFeaturizer \n",
    "compound_featurizers = [fingerprints32(), fingerprints64(), fingerprints128(), fingerprints256(), fingerprints512()]\n",
    "complex_featurizers = [GridFeaturizer(voxel_width=16.0, feature_types=\"voxel_combined\", voxel_feature_types=[\"ecfp\",\n",
    "                                      \"splif\", \"hbond\", \"pi_stack\", \"cation_pi\", \"salt_bridge\"], ecfp_power=5, splif_power=5,\n",
    "                                     parallel=True, flatten=True)]\n",
    "\n",
    "featurizers = compound_featurizers + complex_featurizers\n",
    "featurizer = DataFeaturizer(tasks=[\"label\"],\n",
    "                            smiles_field=\"smiles\",\n",
    "                            protein_pdb_field=\"protein_pdb\",\n",
    "                            ligand_pdb_field=\"ligand_pdb\",\n",
    "                            compound_featurizers=compound_featurizers,\n",
    "                            complex_featurizers=complex_featurizers,\n",
    "                            id_field=\"complex_id\",\n",
    "                            verbose=False)\n",
    "featurized_samples = featurizer.featurize(dataset_file, feature_dir, samples_dir,\n",
    "                                          shard_size=100)\n",
    "print(\"Done featurizing.\")\n",
    "train_dir, test_dir = tempfile.mkdtemp(), tempfile.mkdtemp()\n",
    "splittype=\"scaffold\"\n",
    "train_samples, test_samples = featurized_samples.train_test_split(\n",
    "    splittype, train_dir, test_dir)\n",
    "\n",
    "task_types = {\"label\": \"regression\"}\n",
    "\n",
    "\n",
    "performance = pd.DataFrame()\n",
    "all_featurizers = compound_featurizers + complex_featurizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_file= \"../datasets/pdbbind_core_df.pkl.gz\"\n",
    "from deepchem.utils.save import load_from_disk\n",
    "from deepchem.featurizers.featurize import DataFeaturizer\n",
    "dataset = load_from_disk(dataset_file)\n",
    "\n",
    "from imp import reload\n",
    "import deepchem.featurizers.grid_featurizer\n",
    "reload(deepchem.featurizers.grid_featurizer)\n",
    "from deepchem.featurizers.grid_featurizer import GridFeaturizer \n",
    "import deepchem.featurizers.featurize\n",
    "reload(deepchem.featurizers.featurize)\n",
    "from deepchem.featurizers.featurize import DataFeaturizer\n",
    "\n",
    "compound_featurizers = []\n",
    "complex_featurizers = [GridFeaturizer(voxel_width=16.0, feature_types=\"voxel_combined\", voxel_feature_types=[\"ecfp\",\n",
    "                                      \"splif\", \"hbond\", \"pi_stack\", \"cation_pi\", \"salt_bridge\"], ecfp_power=5, splif_power=5,\n",
    "                                     parallel=True, flatten=True)]\n",
    "\n",
    "import tempfile\n",
    "feature_dir = tempfile.mkdtemp()\n",
    "samples_dir = tempfile.mkdtemp()\n",
    "\n",
    "featurizers = compound_featurizers + complex_featurizers\n",
    "featurizer = DataFeaturizer(tasks=[\"label\"],\n",
    "                            smiles_field=\"smiles\",\n",
    "                            protein_pdb_field=\"protein_pdb\",\n",
    "                            ligand_pdb_field=\"ligand_pdb\",\n",
    "                            compound_featurizers=compound_featurizers,\n",
    "                            complex_featurizers=complex_featurizers,\n",
    "                            id_field=\"complex_id\",\n",
    "                            verbose=False)\n",
    "featurized_samples = featurizer.featurize(dataset_file, feature_dir, samples_dir,\n",
    "                                          shard_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving predictions to <open file '<fdopen>', mode 'w+b' at 0x7f2c5cadc8a0>\n",
      "Saving model performance scores to <open file '<fdopen>', mode 'w+b' at 0x7f2c5cadc150>\n",
      "Saving predictions to <open file '<fdopen>', mode 'w+b' at 0x7f2c5cadc300>\n",
      "Saving model performance scores to <open file '<fdopen>', mode 'w+b' at 0x7f2c5cadc780>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_name</th>\n",
       "      <th>r2_score</th>\n",
       "      <th>rms_error</th>\n",
       "      <th>split</th>\n",
       "      <th>featurizer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>label</td>\n",
       "      <td>0.845777</td>\n",
       "      <td>0.866417</td>\n",
       "      <td>train</td>\n",
       "      <td>&lt;class 'deepchem.featurizers.grid_featurizer.G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>label</td>\n",
       "      <td>0.326259</td>\n",
       "      <td>1.826853</td>\n",
       "      <td>test</td>\n",
       "      <td>&lt;class 'deepchem.featurizers.grid_featurizer.G...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  task_name  r2_score  rms_error  split  \\\n",
       "0     label  0.845777   0.866417  train   \n",
       "0     label  0.326259   1.826853   test   \n",
       "\n",
       "                                          featurizer  \n",
       "0  <class 'deepchem.featurizers.grid_featurizer.G...  \n",
       "0  <class 'deepchem.featurizers.grid_featurizer.G...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir, test_dir = tempfile.mkdtemp(), tempfile.mkdtemp()\n",
    "splittype=\"scaffold\"\n",
    "train_samples, test_samples = featurized_samples.train_test_split(\n",
    "    splittype, train_dir, test_dir)\n",
    "\n",
    "task_types = {\"label\": \"regression\"}\n",
    "import pandas as pd\n",
    "performance = pd.DataFrame()\n",
    "import deepchem.models.standard\n",
    "reload(deepchem.models.standard)\n",
    "from deepchem.models.standard import SklearnModel\n",
    "from deepchem.utils.dataset import Dataset\n",
    "from deepchem.utils.evaluate import Evaluator\n",
    "\n",
    "for feature_type in complex_featurizers:\n",
    "    train_dataset = Dataset(data_dir=train_dir, samples=train_samples, \n",
    "                        featurizers=[feature_type], tasks=[\"label\"])\n",
    "    test_dataset = Dataset(data_dir=test_dir, samples=test_samples, \n",
    "                       featurizers=[feature_type], tasks=[\"label\"])\n",
    "\n",
    "\n",
    "    input_transforms = [\"normalize\", \"truncate\"]\n",
    "    output_transforms = [\"normalize\"]\n",
    "    train_dataset.transform(input_transforms, output_transforms)\n",
    "    test_dataset.transform(input_transforms, output_transforms)\n",
    "\n",
    "    model_params = {\"data_shape\": train_dataset.get_data_shape()}\n",
    "\n",
    "    model = SklearnModel(task_types, model_params, model_instance=RandomForestRegressor())\n",
    "    model.fit(train_dataset)\n",
    "    model_dir = tempfile.mkdtemp()\n",
    "    model.save(model_dir)\n",
    "\n",
    "\n",
    "    evaluator = Evaluator(model, train_dataset, verbose=True)\n",
    "    with tempfile.NamedTemporaryFile() as train_csv_out:\n",
    "      with tempfile.NamedTemporaryFile() as train_stats_out:\n",
    "        _, train_r2score = evaluator.compute_model_performance(\n",
    "            train_csv_out, train_stats_out)\n",
    "\n",
    "    evaluator = Evaluator(model, test_dataset, verbose=True)\n",
    "    with tempfile.NamedTemporaryFile() as test_csv_out:\n",
    "      with tempfile.NamedTemporaryFile() as test_stats_out:\n",
    "        _, test_r2score = evaluator.compute_model_performance(\n",
    "            test_csv_out, test_stats_out)\n",
    "\n",
    "    train_test_performance = pd.concat([train_r2score, test_r2score])\n",
    "    train_test_performance[\"split\"] = [\"train\", \"test\"]\n",
    "    train_test_performance[\"featurizer\"] = [feature_type.__class__, feature_type.__class__]\n",
    "    performance = pd.concat([performance, train_test_performance])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "Starting epoch 6\n",
      "Starting epoch 7\n",
      "Starting epoch 8\n",
      "Starting epoch 9\n",
      "Starting epoch 10\n",
      "Starting epoch 11\n",
      "Starting epoch 12\n",
      "Starting epoch 13\n",
      "Starting epoch 14\n",
      "Starting epoch 15\n",
      "Starting epoch 16\n",
      "Starting epoch 17\n",
      "Starting epoch 18\n",
      "Starting epoch 19\n",
      "Starting epoch 20\n",
      "Starting epoch 21\n",
      "Starting epoch 22\n",
      "Starting epoch 23\n",
      "Starting epoch 24\n",
      "Starting epoch 25\n",
      "Saving predictions to <open file '<fdopen>', mode 'w+b' at 0x7f2c636a2ae0>\n",
      "Saving model performance scores to <open file '<fdopen>', mode 'w+b' at 0x7f2c681aa5d0>\n",
      "  task_name  r2_score  rms_error  learning_rate  nb_hidden  dropout activation\n",
      "0     label  0.357532   1.809035          0.001          1        0       relu\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "Starting epoch 6\n",
      "Starting epoch 7\n",
      "Starting epoch 8\n",
      "Starting epoch 9\n",
      "Starting epoch 10\n",
      "Starting epoch 11\n",
      "Starting epoch 12\n",
      "Starting epoch 13\n",
      "Starting epoch 14\n",
      "Starting epoch 15\n",
      "Starting epoch 16\n",
      "Starting epoch 17\n",
      "Starting epoch 18\n",
      "Starting epoch 19\n",
      "Starting epoch 20\n",
      "Starting epoch 21\n",
      "Starting epoch 22\n",
      "Starting epoch 23\n",
      "Starting epoch 24\n",
      "Starting epoch 25\n",
      "Saving predictions to <open file '<fdopen>', mode 'w+b' at 0x7f2c5e122e40>\n",
      "Saving model performance scores to <open file '<fdopen>', mode 'w+b' at 0x7f2c681aa420>\n",
      "  task_name  r2_score  rms_error  learning_rate  nb_hidden  dropout activation\n",
      "0     label  0.291173   1.900166          0.001          1      0.1       relu\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "Starting epoch 6\n",
      "Starting epoch 7\n",
      "Starting epoch 8\n",
      "Starting epoch 9\n",
      "Starting epoch 10\n",
      "Starting epoch 11\n",
      "Starting epoch 12\n",
      "Starting epoch 13\n",
      "Starting epoch 14\n",
      "Starting epoch 15\n",
      "Starting epoch 16\n",
      "Starting epoch 17\n",
      "Starting epoch 18\n",
      "Starting epoch 19\n",
      "Starting epoch 20\n",
      "Starting epoch 21\n",
      "Starting epoch 22\n",
      "Starting epoch 23\n",
      "Starting epoch 24\n",
      "Starting epoch 25\n",
      "Saving predictions to <open file '<fdopen>', mode 'w+b' at 0x7f2c67051540>\n",
      "Saving model performance scores to <open file '<fdopen>', mode 'w+b' at 0x7f2c5e122e40>\n",
      "  task_name  r2_score  rms_error  learning_rate  nb_hidden  dropout activation\n",
      "0     label -0.083918   2.349739          0.001          1     0.25       relu\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "Starting epoch 6\n",
      "Starting epoch 7\n",
      "Starting epoch 8\n",
      "Starting epoch 9\n",
      "Starting epoch 10\n",
      "Starting epoch 11\n",
      "Starting epoch 12\n",
      "Starting epoch 13\n",
      "Starting epoch 14\n",
      "Starting epoch 15\n",
      "Starting epoch 16\n",
      "Starting epoch 17\n",
      "Starting epoch 18\n",
      "Starting epoch 19\n",
      "Starting epoch 20\n",
      "Starting epoch 21\n",
      "Starting epoch 22\n",
      "Starting epoch 23\n",
      "Starting epoch 24\n",
      "Starting epoch 25\n",
      "Saving predictions to <open file '<fdopen>', mode 'w+b' at 0x7f2c636a2ae0>\n",
      "Saving model performance scores to <open file '<fdopen>', mode 'w+b' at 0x7f2c67051540>\n",
      "  task_name  r2_score  rms_error  learning_rate  nb_hidden  dropout activation\n",
      "0     label  0.255474   1.947428          0.001          2        0       relu\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "Starting epoch 6\n",
      "Starting epoch 7\n",
      "Starting epoch 8\n",
      "Starting epoch 9\n",
      "Starting epoch 10\n",
      "Starting epoch 11\n",
      "Starting epoch 12\n",
      "Starting epoch 13\n",
      "Starting epoch 14\n",
      "Starting epoch 15\n",
      "Starting epoch 16\n",
      "Starting epoch 17\n",
      "Starting epoch 18\n",
      "Starting epoch 19\n",
      "Starting epoch 20\n",
      "Starting epoch 21\n",
      "Starting epoch 22\n",
      "Starting epoch 23\n",
      "Starting epoch 24\n",
      "Starting epoch 25\n",
      "Saving predictions to <open file '<fdopen>', mode 'w+b' at 0x7f2c636a2ed0>\n",
      "Saving model performance scores to <open file '<fdopen>', mode 'w+b' at 0x7f2c636a2ae0>\n",
      "  task_name  r2_score  rms_error  learning_rate  nb_hidden  dropout activation\n",
      "0     label -0.421756   2.691126          0.001          2      0.1       relu\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "Starting epoch 6\n",
      "Starting epoch 7\n",
      "Starting epoch 8\n",
      "Starting epoch 9\n",
      "Starting epoch 10\n",
      "Starting epoch 11\n",
      "Starting epoch 12\n",
      "Starting epoch 13\n",
      "Starting epoch 14\n",
      "Starting epoch 15\n",
      "Starting epoch 16\n",
      "Starting epoch 17\n",
      "Starting epoch 18\n",
      "Starting epoch 19\n",
      "Starting epoch 20\n",
      "Starting epoch 21\n",
      "Starting epoch 22\n",
      "Starting epoch 23\n",
      "Starting epoch 24\n",
      "Starting epoch 25\n",
      "Saving predictions to <open file '<fdopen>', mode 'w+b' at 0x7f2c636a2780>\n",
      "Saving model performance scores to <open file '<fdopen>', mode 'w+b' at 0x7f2c636a2ed0>\n",
      "  task_name  r2_score  rms_error  learning_rate  nb_hidden  dropout activation\n",
      "0     label -0.147274   2.417436          0.001          2     0.25       relu\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "Starting epoch 6\n",
      "Starting epoch 7\n",
      "Starting epoch 8\n",
      "Starting epoch 9\n",
      "Starting epoch 10\n",
      "Starting epoch 11\n",
      "Starting epoch 12\n",
      "Starting epoch 13\n",
      "Starting epoch 14\n",
      "Starting epoch 15\n",
      "Starting epoch 16\n",
      "Starting epoch 17\n",
      "Starting epoch 18\n",
      "Starting epoch 19\n",
      "Starting epoch 20\n",
      "Starting epoch 21\n",
      "Starting epoch 22\n",
      "Starting epoch 23\n",
      "Starting epoch 24\n",
      "Starting epoch 25\n",
      "Saving predictions to <open file '<fdopen>', mode 'w+b' at 0x7f2c636a2540>\n",
      "Saving model performance scores to <open file '<fdopen>', mode 'w+b' at 0x7f2c636a2780>\n",
      "  task_name  r2_score  rms_error  learning_rate  nb_hidden  dropout activation\n",
      "0     label  0.350098   1.819472          0.001          3        0       relu\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "Starting epoch 6\n",
      "Starting epoch 7\n",
      "Starting epoch 8\n",
      "Starting epoch 9\n",
      "Starting epoch 10\n",
      "Starting epoch 11\n",
      "Starting epoch 12\n",
      "Starting epoch 13\n",
      "Starting epoch 14\n",
      "Starting epoch 15\n",
      "Starting epoch 16\n",
      "Starting epoch 17\n",
      "Starting epoch 18\n",
      "Starting epoch 19\n",
      "Starting epoch 20\n",
      "Starting epoch 21\n",
      "Starting epoch 22\n",
      "Starting epoch 23\n",
      "Starting epoch 24\n",
      "Starting epoch 25\n",
      "Saving predictions to <open file '<fdopen>', mode 'w+b' at 0x7f2c539d24b0>\n",
      "Saving model performance scores to <open file '<fdopen>', mode 'w+b' at 0x7f2c636a2540>\n",
      "  task_name  r2_score  rms_error  learning_rate  nb_hidden  dropout activation\n",
      "0     label  0.242379   1.964479          0.001          3      0.1       relu\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "Starting epoch 6\n",
      "Starting epoch 7\n",
      "Starting epoch 8\n",
      "Starting epoch 9\n",
      "Starting epoch 10\n",
      "Starting epoch 11\n",
      "Starting epoch 12\n",
      "Starting epoch 13\n",
      "Starting epoch 14\n",
      "Starting epoch 15\n",
      "Starting epoch 16\n",
      "Starting epoch 17\n",
      "Starting epoch 18\n",
      "Starting epoch 19\n",
      "Starting epoch 20\n",
      "Starting epoch 21\n",
      "Starting epoch 22\n",
      "Starting epoch 23\n",
      "Starting epoch 24\n",
      "Starting epoch 25\n",
      "Saving predictions to <open file '<fdopen>', mode 'w+b' at 0x7f2c636a2390>\n",
      "Saving model performance scores to <open file '<fdopen>', mode 'w+b' at 0x7f2c636a2f60>\n",
      "  task_name  r2_score  rms_error  learning_rate  nb_hidden  dropout activation\n",
      "0     label  0.169226   2.057136          0.001          3     0.25       relu\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "Starting epoch 6\n",
      "Starting epoch 7\n",
      "Starting epoch 8\n",
      "Starting epoch 9\n",
      "Starting epoch 10\n",
      "Starting epoch 11\n",
      "Starting epoch 12\n",
      "Starting epoch 13\n",
      "Starting epoch 14\n",
      "Starting epoch 15\n",
      "Starting epoch 16\n",
      "Starting epoch 17\n",
      "Starting epoch 18\n",
      "Starting epoch 19\n",
      "Starting epoch 20\n",
      "Starting epoch 21\n",
      "Starting epoch 22\n",
      "Starting epoch 23\n",
      "Starting epoch 24\n",
      "Starting epoch 25\n",
      "Saving predictions to <open file '<fdopen>', mode 'w+b' at 0x7f2c5e122e40>\n",
      "Saving model performance scores to <open file '<fdopen>', mode 'w+b' at 0x7f2c670519c0>\n",
      "  task_name  r2_score  rms_error  learning_rate  nb_hidden  dropout activation\n",
      "0     label  0.248035   1.957133          0.001         10        0       relu\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "Starting epoch 6\n",
      "Starting epoch 7\n",
      "Starting epoch 8\n",
      "Starting epoch 9\n",
      "Starting epoch 10\n",
      "Starting epoch 11\n",
      "Starting epoch 12\n",
      "Starting epoch 13\n",
      "Starting epoch 14\n",
      "Starting epoch 15\n",
      "Starting epoch 16\n",
      "Starting epoch 17\n",
      "Starting epoch 18\n",
      "Starting epoch 19\n",
      "Starting epoch 20\n",
      "Starting epoch 21\n",
      "Starting epoch 22\n",
      "Starting epoch 23\n",
      "Starting epoch 24\n",
      "Starting epoch 25\n",
      "Saving predictions to <open file '<fdopen>', mode 'w+b' at 0x7f2c636a2030>\n",
      "Saving model performance scores to <open file '<fdopen>', mode 'w+b' at 0x7f2c5e122e40>\n",
      "  task_name  r2_score  rms_error  learning_rate  nb_hidden  dropout activation\n",
      "0     label -0.038015   2.299446          0.001         10      0.1       relu\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "Starting epoch 6\n",
      "Starting epoch 7\n",
      "Starting epoch 8\n",
      "Starting epoch 9\n",
      "Starting epoch 10\n",
      "Starting epoch 11\n",
      "Starting epoch 12\n",
      "Starting epoch 13\n",
      "Starting epoch 14\n",
      "Starting epoch 15\n",
      "Starting epoch 16\n",
      "Starting epoch 17\n",
      "Starting epoch 18\n",
      "Starting epoch 19\n",
      "Starting epoch 20\n",
      "Starting epoch 21\n",
      "Starting epoch 22\n",
      "Starting epoch 23\n",
      "Starting epoch 24\n",
      "Starting epoch 25\n",
      "Saving predictions to <open file '<fdopen>', mode 'w+b' at 0x7f2c636a28a0>\n",
      "Saving model performance scores to <open file '<fdopen>', mode 'w+b' at 0x7f2c636a2030>\n",
      "  task_name  r2_score  rms_error  learning_rate  nb_hidden  dropout activation\n",
      "0     label  0.381529   1.774929          0.001         10     0.25       relu\n",
      "  task_name  r2_score  rms_error  learning_rate  nb_hidden  dropout activation\n",
      "0     label  0.357532   1.809035          0.001          1     0.00       relu\n",
      "0     label  0.291173   1.900166          0.001          1     0.10       relu\n",
      "0     label -0.083918   2.349739          0.001          1     0.25       relu\n",
      "0     label  0.255474   1.947428          0.001          2     0.00       relu\n",
      "0     label -0.421756   2.691126          0.001          2     0.10       relu\n",
      "0     label -0.147274   2.417436          0.001          2     0.25       relu\n",
      "0     label  0.350098   1.819472          0.001          3     0.00       relu\n",
      "0     label  0.242379   1.964479          0.001          3     0.10       relu\n",
      "0     label  0.169226   2.057136          0.001          3     0.25       relu\n",
      "0     label  0.248035   1.957133          0.001         10     0.00       relu\n",
      "0     label -0.038015   2.299446          0.001         10     0.10       relu\n",
      "0     label  0.381529   1.774929          0.001         10     0.25       relu\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import deepchem.models.standard\n",
    "from deepchem.models.deep import SingleTaskDNN\n",
    "from deepchem.utils.dataset import Dataset\n",
    "from deepchem.utils.evaluate import Evaluator\n",
    "\n",
    "train_dir, validation_dir, test_dir = tempfile.mkdtemp(), tempfile.mkdtemp(), tempfile.mkdtemp()\n",
    "splittype=\"random\"\n",
    "train_samples, validation_samples, test_samples = featurized_samples.train_valid_test_split(\n",
    "    splittype, train_dir, validation_dir, test_dir)\n",
    "\n",
    "task_types = {\"label\": \"regression\"}\n",
    "performance = pd.DataFrame()\n",
    "\n",
    "\n",
    "feature_type = complex_featurizers[0]\n",
    "\n",
    "hyperparameter_df = pd.DataFrame()\n",
    "train_dataset = Dataset(data_dir=train_dir, samples=train_samples, \n",
    "                    featurizers=[feature_type], tasks=[\"label\"])\n",
    "validation_dataset = Dataset(data_dir=validation_dir, samples=validation_samples, \n",
    "                    featurizers=[feature_type], tasks=[\"label\"])\n",
    "test_dataset = Dataset(data_dir=test_dir, samples=test_samples, \n",
    "                   featurizers=[feature_type], tasks=[\"label\"])\n",
    "\n",
    "\n",
    "input_transforms = [\"normalize\", \"truncate\"]\n",
    "output_transforms = [\"normalize\"]\n",
    "train_dataset.transform(input_transforms, output_transforms)\n",
    "validation_dataset.transform(input_transforms, output_transforms)\n",
    "test_dataset.transform(input_transforms, output_transforms)\n",
    "\n",
    "model_params = {\"data_shape\": train_dataset.get_data_shape(),\n",
    "                \"batch_size\": 128, \"decay\": 1e-4,\n",
    "                \"init\": \"glorot_uniform\", \n",
    "                \"momentum\": .9, \"nesterov\": False,\n",
    "                \"nb_epoch\": 25}\n",
    "\n",
    "learning_rate_vals = [0.001]\n",
    "nb_hidden_vals = [1, 2, 3, 10]\n",
    "dropout_vals = [0.0, 0.1, 0.25]\n",
    "activation_vals = [\"relu\"]\n",
    "\n",
    "for learning_rate in learning_rate_vals:\n",
    "    model_params[\"learning_rate\"] = learning_rate\n",
    "    for nb_hidden in nb_hidden_vals:\n",
    "        model_params[\"nb_hidden\"] = nb_hidden\n",
    "        for dropout in dropout_vals:\n",
    "            model_params[\"dropout\"] = dropout\n",
    "            for activation in activation_vals:\n",
    "                model_params[\"activation\"] = activation\n",
    "                model = SingleTaskDNN(task_types, model_params)\n",
    "                model.fit(train_dataset)\n",
    "                evaluator = Evaluator(model, validation_dataset, verbose=True)\n",
    "                with tempfile.NamedTemporaryFile() as validation_csv_out:\n",
    "                  with tempfile.NamedTemporaryFile() as validation_stats_out:\n",
    "                    _, validation_r2score = evaluator.compute_model_performance(\n",
    "                        validation_csv_out, validation_stats_out)\n",
    "                validation_r2score[\"learning_rate\"] = learning_rate\n",
    "                validation_r2score[\"nb_hidden\"] = nb_hidden\n",
    "                validation_r2score[\"dropout\"] = dropout\n",
    "                validation_r2score[\"activation\"] = activation\n",
    "                print(validation_r2score)\n",
    "                hyperparameter_df = pd.concat([hyperparameter_df, validation_r2score])\n",
    "print(hyperparameter_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task_name           label\n",
      "r2_score         0.381529\n",
      "rms_error         1.77493\n",
      "learning_rate       0.001\n",
      "nb_hidden              10\n",
      "dropout              0.25\n",
      "activation           relu\n",
      "Name: 0, dtype: object\n",
      "{'decay': 0.0001, 'data_shape': (135,), 'nb_epoch': 100, 'batch_size': 100, 'nesterov': False, 'init': 'glorot_uniform', 'activation': 'relu', 'nb_hidden': 10, 'dropout': 0.25, 'learning_rate': 0.001, 'momentum': 0.9}\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "Starting epoch 6\n",
      "Starting epoch 7\n",
      "Starting epoch 8\n",
      "Starting epoch 9\n",
      "Starting epoch 10\n",
      "Starting epoch 11\n",
      "Starting epoch 12\n",
      "Starting epoch 13\n",
      "Starting epoch 14\n",
      "Starting epoch 15\n",
      "Starting epoch 16\n",
      "Starting epoch 17\n",
      "Starting epoch 18\n",
      "Starting epoch 19\n",
      "Starting epoch 20\n",
      "Starting epoch 21\n",
      "Starting epoch 22\n",
      "Starting epoch 23\n",
      "Starting epoch 24\n",
      "Starting epoch 25\n",
      "Starting epoch 26\n",
      "Starting epoch 27\n",
      "Starting epoch 28\n",
      "Starting epoch 29\n",
      "Starting epoch 30\n",
      "Starting epoch 31\n",
      "Starting epoch 32\n",
      "Starting epoch 33\n",
      "Starting epoch 34\n",
      "Starting epoch 35\n",
      "Starting epoch 36\n",
      "Starting epoch 37\n",
      "Starting epoch 38\n",
      "Starting epoch 39\n",
      "Starting epoch 40\n",
      "Starting epoch 41\n",
      "Starting epoch 42\n",
      "Starting epoch 43\n",
      "Starting epoch 44\n",
      "Starting epoch 45\n",
      "Starting epoch 46\n",
      "Starting epoch 47\n",
      "Starting epoch 48\n",
      "Starting epoch 49\n",
      "Starting epoch 50\n",
      "Starting epoch 51\n",
      "Starting epoch 52\n",
      "Starting epoch 53\n",
      "Starting epoch 54\n",
      "Starting epoch 55\n",
      "Starting epoch 56\n",
      "Starting epoch 57\n",
      "Starting epoch 58\n",
      "Starting epoch 59\n",
      "Starting epoch 60\n",
      "Starting epoch 61\n",
      "Starting epoch 62\n",
      "Starting epoch 63\n",
      "Starting epoch 64\n",
      "Starting epoch 65\n",
      "Starting epoch 66\n",
      "Starting epoch 67\n",
      "Starting epoch 68\n",
      "Starting epoch 69\n",
      "Starting epoch 70\n",
      "Starting epoch 71\n",
      "Starting epoch 72\n",
      "Starting epoch 73\n",
      "Starting epoch 74\n",
      "Starting epoch 75\n",
      "Starting epoch 76\n",
      "Starting epoch 77\n",
      "Starting epoch 78\n",
      "Starting epoch 79\n",
      "Starting epoch 80\n",
      "Starting epoch 81\n",
      "Starting epoch 82\n",
      "Starting epoch 83\n",
      "Starting epoch 84\n",
      "Starting epoch 85\n",
      "Starting epoch 86\n",
      "Starting epoch 87\n",
      "Starting epoch 88\n",
      "Starting epoch 89\n",
      "Starting epoch 90\n",
      "Starting epoch 91\n",
      "Starting epoch 92\n",
      "Starting epoch 93\n",
      "Starting epoch 94\n",
      "Starting epoch 95\n",
      "Starting epoch 96\n",
      "Starting epoch 97\n",
      "Starting epoch 98\n",
      "Starting epoch 99\n",
      "Starting epoch 100\n",
      "Saving predictions to <open file '<fdopen>', mode 'w+b' at 0x7f2c539d24b0>\n",
      "Saving model performance scores to <open file '<fdopen>', mode 'w+b' at 0x7f2c539d20c0>\n",
      "  task_name  r2_score  rms_error\n",
      "0     label  0.287529   1.484681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/enf/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:1: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "hyperparameter_df = hyperparameter_df.sort(['r2_score'], ascending=[0])\n",
    "best_model = hyperparameter_df.iloc[0]\n",
    "model_params[\"batch_size\"] = 100\n",
    "model_params[\"learning_rate\"] = 0.001 #best_model[\"learning_rate\"]\n",
    "model_params[\"nb_hidden\"] = best_model[\"nb_hidden\"]\n",
    "model_params[\"dropout\"] = best_model[\"dropout\"]\n",
    "model_params[\"activation\"] = best_model[\"activation\"]\n",
    "model_params[\"nb_epoch\"] = 100\n",
    "print(hyperparameter_df.iloc[0])\n",
    "print(model_params)\n",
    "\n",
    "model = SingleTaskDNN(task_types, model_params)\n",
    "model.fit(train_dataset)\n",
    "evaluator = Evaluator(model, test_dataset, verbose=True)\n",
    "with tempfile.NamedTemporaryFile() as test_csv_out:\n",
    "  with tempfile.NamedTemporaryFile() as test_stats_out:\n",
    "    _, test_r2score = evaluator.compute_model_performance(\n",
    "        test_csv_out, test_stats_out)\n",
    "\n",
    "print(test_r2score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving predictions to <open file '<fdopen>', mode 'w+b' at 0x7f2c636a2c00>\n",
      "Saving model performance scores to <open file '<fdopen>', mode 'w+b' at 0x7f2c3d0b38a0>\n",
      "  task_name  r2_score  rms_error\n",
      "0     label  0.407127   1.354348\n"
     ]
    }
   ],
   "source": [
    "model = SklearnModel(task_types, model_params, model_instance=RandomForestRegressor(n_estimators=1000))\n",
    "model.fit(train_dataset)\n",
    "evaluator = Evaluator(model, test_dataset, verbose=True)\n",
    "with tempfile.NamedTemporaryFile() as test_csv_out:\n",
    "  with tempfile.NamedTemporaryFile() as test_stats_out:\n",
    "    _, test_r2score = evaluator.compute_model_performance(\n",
    "        test_csv_out, test_stats_out)\n",
    "\n",
    "print(test_r2score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we have computed three separate featurizations -- ECFP4, RDKitDescriptors, and NNScore -- in this example we choose to use the RDKitDescriptors featurization. This will serve as a baseline as you apply more advanced featurization schemes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is essential for many ML methods, depending on the data type, to perform preprocessing in order to attain optimal performance. Here, we choose to normalize and truncate the inputs (X, the featurized complexes) while normalizing the output (y, the binding affinities):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To recap, the initial dataset has now been featurized, split into train and test sets, and transformed. We are now ready to learn some chemistry! To warm up, let's apply a more traditional but quite robust statistical learning technique: random forests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've fit an Random Forest Regressor on the data, let's evaluate its performance:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare this to performance with a deep neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from deepchem.models import Model\n",
    "\n",
    "task_type = \"regression\"\n",
    "model_params = {\"activation\": \"relu\",\n",
    "              \"dropout\": 0.,\n",
    "              \"momentum\": .9, \"nesterov\": False,\n",
    "              \"decay\": 1e-4, \"batch_size\": 5,\n",
    "              \"nb_epoch\": 10}\n",
    "model_name = \"singletask_deep_regressor\"\n",
    "\n",
    "nb_hidden_vals = [10, 100]\n",
    "learning_rate_vals = [.01, .001]\n",
    "init_vals = [\"glorot_uniform\"]\n",
    "hyperparameters = [nb_hidden_vals, learning_rate_vals, init_vals]\n",
    "hyperparameter_rows = []\n",
    "for hyperparameter_tuple in itertools.product(*hyperparameters):\n",
    "    nb_hidden, learning_rate, init = hyperparameter_tuple\n",
    "    model_params[\"nb_hidden\"] = nb_hidden\n",
    "    model_params[\"learning_rate\"] = learning_rate\n",
    "    model_params[\"init\"] = init\n",
    "\n",
    "    model_dir = tempfile.mkdtemp()\n",
    "\n",
    "    r2_score = create_and_eval_model(train_dataset, test_dataset, task_type,\n",
    "                                     model_params, model_name, model_dir, tasks)\n",
    "\n",
    "    print(\"%s: %s\" % (hyperparameter_tuple, r2_score))\n",
    "    hyperparameter_rows.append(list(hyperparameter_tuple) + [r2_score])\n",
    "\n",
    "    shutil.rmtree(model_dir)\n",
    "\n",
    "hyperparameter_df = pd.DataFrame(hyperparameter_rows,\n",
    "                               columns=('nb_hidden', 'learning_rate',\n",
    "                                        'init', 'r2_score'))\n",
    "\n",
    "hyperparameter_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
