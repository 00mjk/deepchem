{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Setting up imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Automatic pdb calling has been turned OFF\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "No module named featurizers.featurize",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a6ac7c9c202f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdeepchem\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdeepchem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdeepchem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeaturizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeaturize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataFeaturizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdeepchem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeaturizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeaturize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFeaturizedSamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdeepchem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHyperparamOpt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named featurizers.featurize"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pdb off\n",
    "\"\"\"\n",
    "Not Currently Working\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "__author__ = \"Joseph Gomes\"\n",
    "__copyright__ = \"Copyright 2016, Stanford University\"\n",
    "__license__ = \"LGPL\"\n",
    "\n",
    "import os\n",
    "import unittest\n",
    "import tempfile\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import numpy.random\n",
    "\n",
    "from deepchem import metrics\n",
    "from deepchem.data.datasets import Dataset\n",
    "from deepchem.featurizers.featurize import DataFeaturizer\n",
    "from deepchem.featurizers.featurize import FeaturizedSamples\n",
    "from deepchem.hyperparameters import HyperparamOpt\n",
    "from deepchem.metrics import Metric\n",
    "from deepchem.models import Model\n",
    "from deepchem.models.sklearn_models import SklearnModel\n",
    "from deepchem.transformers import NormalizationTransformer\n",
    "from deepchem.utils.evaluate import Evaluator\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating temporary directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_dir = tempfile.mkdtemp()\n",
    "samples_dir = tempfile.mkdtemp()\n",
    "train_dir = tempfile.mkdtemp()\n",
    "valid_dir = tempfile.mkdtemp()\n",
    "test_dir = tempfile.mkdtemp()\n",
    "model_dir = tempfile.mkdtemp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up model variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchem.featurizers.coulomb_matrices import CoulombMatrixEig\n",
    "compound_featurizers = [CoulombMatrixEig(23, remove_hydrogens=False)]\n",
    "complex_featurizers = []\n",
    "tasks = [\"atomization_energy\"]\n",
    "task_type = \"regression\"\n",
    "task_types = {task: task_type for task in tasks}\n",
    "input_file = \"../datasets/gdb1k.sdf\"\n",
    "smiles_field = \"smiles\"\n",
    "mol_field = \"mol\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load featurized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizers = compound_featurizers + complex_featurizers\n",
    "featurizer = DataFeaturizer(tasks=tasks,\n",
    "                            smiles_field=smiles_field,\n",
    "                            mol_field=mol_field,\n",
    "                            compound_featurizers=compound_featurizers,\n",
    "                            complex_featurizers=complex_featurizers, verbosity=\"high\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "featurized_samples = featurizer.featurize(input_file, feature_dir, samples_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform Train, Validation, and Testing Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchem.splits import RandomSplitter\n",
    "random_splitter = RandomSplitter()\n",
    "train_samples, valid_samples, test_samples = random_splitter.train_valid_test_split(featurized_samples,\n",
    "    train_dir, valid_dir, test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(data_dir=train_dir, samples=train_samples, \n",
    "                        featurizers=featurizers, tasks=tasks)\n",
    "valid_dataset = Dataset(data_dir=valid_dir, samples=valid_samples, \n",
    "                        featurizers=featurizers, tasks=tasks)\n",
    "test_dataset = Dataset(data_dir=test_dir, samples=test_samples, \n",
    "                       featurizers=featurizers, tasks=tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_transformers = [NormalizationTransformer(transform_X=True, dataset=train_dataset)]\n",
    "output_transformers = [NormalizationTransformer(transform_y=True, dataset=train_dataset)]\n",
    "transformers = input_transformers + output_transformers\n",
    "for transformer in transformers:\n",
    "    transformer.transform(train_dataset)\n",
    "for transformer in transformers:\n",
    "    transformer.transform(valid_dataset)\n",
    "for transformer in transformers:\n",
    "    transformer.transform(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Fit Random Forest with hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def rf_model_builder(tasks, task_types, params_dict, model_dir, verbosity=None):\n",
    "    \"\"\"Builds random forests given hyperparameters.\n",
    "    \n",
    "    \"\"\"\n",
    "    n_estimators = params_dict[\"n_estimators\"]\n",
    "    max_features = params_dict[\"max_features\"]\n",
    "    return SklearnModel(\n",
    "        tasks, task_types, params_dict, model_dir,\n",
    "        mode=\"regression\",\n",
    "        model_instance=RandomForestRegressor(n_estimators=n_estimators,\n",
    "                                             max_features=max_features))\n",
    "\n",
    "params_dict = {\n",
    "    \"n_estimators\": [10, 100],\n",
    "    \"data_shape\": [train_dataset.get_data_shape()],\n",
    "    \"max_features\": [\"auto\"],\n",
    "    }\n",
    "\n",
    "metric = Metric(metrics.mean_absolute_error)\n",
    "optimizer = HyperparamOpt(rf_model_builder, tasks, task_types, verbosity=\"low\")       \n",
    "best_model, best_hyperparams, all_results = optimizer.hyperparam_search(              \n",
    "    params_dict, train_dataset, valid_dataset, output_transformers,                     \n",
    "    metric, use_max=\"False\", logdir=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kr_model_builder(tasks, task_types, params_dict, model_dir, verbosity=None):\n",
    "    \"\"\"Builds random forests given hyperparameters.\n",
    "\n",
    "    \"\"\"\n",
    "    kernel = params_dict[\"kernel\"]\n",
    "    alpha = params_dict[\"alpha\"]\n",
    "    gamma = params_dict[\"gamma\"]\n",
    "    return SklearnModel(\n",
    "        tasks, task_types, params_dict, model_dir,\n",
    "        mode=\"regression\",\n",
    "        model_instance=KernelRidge(alpha=alpha,kernel=kernel,gamma=gamma))\n",
    "\n",
    "params_dict = {\n",
    "    \"kernel\": [\"laplacian\"],\n",
    "    \"alpha\": [0.0001],\n",
    "    \"gamma\": [0.0001]\n",
    "    }\n",
    "\n",
    "metric = Metric(metrics.mean_absolute_error)\n",
    "optimizer = HyperparamOpt(kr_model_builder, tasks, task_types, verbosity=\"low\")       \n",
    "best_model, best_hyperparams, all_results = optimizer.hyperparam_search(              \n",
    "    params_dict, train_dataset, valid_dataset, output_transformers,                     \n",
    "    metric, use_max=\"False\", logdir=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
