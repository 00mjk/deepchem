{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dibya/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/dibya/anaconda2/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/dibya/deepchem')\n",
    "import deepchem as dc\n",
    "import tensorflow as tf\n",
    "from deepchem.models.tensorgraph.layers import Layer, Input, Reshape, Flatten\n",
    "from deepchem.models.tensorgraph.layers import Dense, SoftMaxCrossEntropy, ReduceMean, SoftMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-98299b294029>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNumpyDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNumpyDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dc' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "train = dc.data.NumpyDataset(mnist.train.images, mnist.train.labels)\n",
    "valid = dc.data.NumpyDataset(mnist.validation.images, mnist.validation.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-57180b2a4988>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dc' is not defined"
     ]
    }
   ],
   "source": [
    "dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TensorGraph' object has no attribute 'add_layer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-2b44f7ddca0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensorboard\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/tmp/mnist'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m784\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TensorGraph' object has no attribute 'add_layer'"
     ]
    }
   ],
   "source": [
    "tg = dc.models.TensorGraph(tensorboard=True, model_dir='/tmp/mnist')\n",
    "feature = Input(shape=(None, 784))\n",
    "tg.add_layer(feature)\n",
    "tg.add_feature(feature)\n",
    "\n",
    "# Images are square 28x28 (batch, height, width, channel)\n",
    "make_image = Reshape(shape=(-1, 28, 28, 1))\n",
    "tg.add_layer(make_image, parents=[feature])\n",
    "\n",
    "class Conv2d(Layer):\n",
    "    def __init__(self, num_outputs, kernel_size=5, **kwargs):\n",
    "        self.num_outputs = num_outputs\n",
    "        self.kernel_size = kernel_size\n",
    "        super(Conv2d, self).__init__(**kwargs)\n",
    "    def __call__(self, *parents):\n",
    "        parent_tensor = parents[0].out_tensor\n",
    "        out_tensor = tf.contrib.layers.conv2d(parent_tensor,\n",
    "                                              num_outputs=self.num_outputs,\n",
    "                                              kernel_size = self.kernel_size,\n",
    "                                              padding=\"SAME\",\n",
    "                                              activation_fn=tf.nn.relu,\n",
    "                                              normalizer_fn=tf.contrib.layers.batch_norm)\n",
    "        self.out_tensor = tf.nn.max_pool(out_tensor, \n",
    "                                         ksize=[1, 2, 2, 1],\n",
    "                                         strides=[1, 2, 2, 1], \n",
    "                                         padding='SAME')\n",
    "        return self.out_tensor\n",
    "conv2d_1 = Conv2d(num_outputs=32)\n",
    "tg.add_layer(conv2d_1, parents=[make_image])\n",
    "\n",
    "conv2d_2 = Conv2d(num_outputs=64)\n",
    "tg.add_layer(conv2d_2, parents=[conv2d_1])\n",
    "\n",
    "flatten = Flatten()\n",
    "tg.add_layer(flatten, parents=[conv2d_2])\n",
    "\n",
    "dense1 = Dense(out_channels=1024, activation_fn=tf.nn.relu)\n",
    "tg.add_layer(dense1, parents=[flatten])\n",
    "\n",
    "dense2 = Dense(out_channels=10)\n",
    "tg.add_layer(dense2, parents=[dense1])\n",
    "\n",
    "label = Input(shape=(None, 10))\n",
    "tg.add_layer(label, parents=list())\n",
    "tg.add_label(label)\n",
    "\n",
    "smce = SoftMaxCrossEntropy()\n",
    "tg.add_layer(smce, parents=[label, dense2])\n",
    "\n",
    "loss = ReduceMean()\n",
    "tg.add_layer(loss, parents=[smce])\n",
    "tg.set_loss(loss)\n",
    "\n",
    "output = SoftMax()\n",
    "tg.add_layer(output, parents=[dense2])\n",
    "tg.add_output(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 10 epochs\n",
      "On batch 0\n",
      "On batch 50\n",
      "On batch 100\n",
      "On batch 150\n",
      "On batch 200\n",
      "On batch 250\n",
      "On batch 300\n",
      "On batch 350\n",
      "On batch 400\n",
      "On batch 450\n",
      "On batch 500\n",
      "On batch 550\n",
      "On batch 600\n",
      "On batch 650\n",
      "On batch 700\n",
      "On batch 750\n",
      "On batch 800\n",
      "On batch 850\n",
      "On batch 900\n",
      "On batch 950\n",
      "On batch 1000\n",
      "On batch 1050\n",
      "Ending epoch 0: Average loss 0.198305\n",
      "On batch 0\n",
      "On batch 50\n",
      "On batch 100\n",
      "On batch 150\n",
      "On batch 200\n",
      "On batch 250\n",
      "On batch 300\n",
      "On batch 350\n",
      "On batch 400\n",
      "On batch 450\n",
      "On batch 500\n",
      "On batch 550\n",
      "On batch 600\n",
      "On batch 650\n",
      "On batch 700\n",
      "On batch 750\n",
      "On batch 800\n",
      "On batch 850\n",
      "On batch 900\n",
      "On batch 950\n",
      "On batch 1000\n",
      "On batch 1050\n",
      "Ending epoch 1: Average loss 0.0536864\n",
      "On batch 0\n",
      "On batch 50\n",
      "On batch 100\n",
      "On batch 150\n",
      "On batch 200\n",
      "On batch 250\n",
      "On batch 300\n",
      "On batch 350\n",
      "On batch 400\n",
      "On batch 450\n",
      "On batch 500\n",
      "On batch 550\n",
      "On batch 600\n",
      "On batch 650\n",
      "On batch 700\n",
      "On batch 750\n",
      "On batch 800\n",
      "On batch 850\n",
      "On batch 900\n",
      "On batch 950\n",
      "On batch 1000\n",
      "On batch 1050\n",
      "Ending epoch 2: Average loss 0.0425871\n",
      "On batch 0\n",
      "On batch 50\n",
      "On batch 100\n",
      "On batch 150\n",
      "On batch 200\n",
      "On batch 250\n",
      "On batch 300\n",
      "On batch 350\n",
      "On batch 400\n",
      "On batch 450\n",
      "On batch 500\n",
      "On batch 550\n",
      "On batch 600\n",
      "On batch 650\n",
      "On batch 700\n",
      "On batch 750\n",
      "On batch 800\n",
      "On batch 850\n",
      "On batch 900\n",
      "On batch 950\n",
      "On batch 1000\n",
      "On batch 1050\n",
      "Ending epoch 3: Average loss 0.0336403\n",
      "On batch 0\n",
      "On batch 50\n",
      "On batch 100\n",
      "On batch 150\n",
      "On batch 200\n",
      "On batch 250\n",
      "On batch 300\n",
      "On batch 350\n",
      "On batch 400\n",
      "On batch 450\n",
      "On batch 500\n",
      "On batch 550\n",
      "On batch 600\n",
      "On batch 650\n",
      "On batch 700\n",
      "On batch 750\n",
      "On batch 800\n",
      "On batch 850\n",
      "On batch 900\n",
      "On batch 950\n",
      "On batch 1000\n",
      "On batch 1050\n",
      "Ending epoch 4: Average loss 0.028042\n",
      "On batch 0\n",
      "On batch 50\n",
      "On batch 100\n",
      "On batch 150\n",
      "On batch 200\n",
      "On batch 250\n",
      "On batch 300\n",
      "On batch 350\n",
      "On batch 400\n",
      "On batch 450\n",
      "On batch 500\n",
      "On batch 550\n",
      "On batch 600\n",
      "On batch 650\n",
      "On batch 700\n",
      "On batch 750\n",
      "On batch 800\n",
      "On batch 850\n",
      "On batch 900\n",
      "On batch 950\n",
      "On batch 1000\n",
      "On batch 1050\n",
      "Ending epoch 5: Average loss 0.0257894\n",
      "On batch 0\n",
      "On batch 50\n",
      "On batch 100\n",
      "On batch 150\n",
      "On batch 200\n",
      "On batch 250\n",
      "On batch 300\n",
      "On batch 350\n",
      "On batch 400\n",
      "On batch 450\n",
      "On batch 500\n",
      "On batch 550\n",
      "On batch 600\n",
      "On batch 650\n",
      "On batch 700\n",
      "On batch 750\n",
      "On batch 800\n",
      "On batch 850\n",
      "On batch 900\n",
      "On batch 950\n",
      "On batch 1000\n",
      "On batch 1050\n",
      "Ending epoch 6: Average loss 0.0187417\n",
      "On batch 0\n",
      "On batch 50\n",
      "On batch 100\n",
      "On batch 150\n",
      "On batch 200\n",
      "On batch 250\n",
      "On batch 300\n",
      "On batch 350\n",
      "On batch 400\n",
      "On batch 450\n",
      "On batch 500\n",
      "On batch 550\n",
      "On batch 600\n",
      "On batch 650\n",
      "On batch 700\n",
      "On batch 750\n",
      "On batch 800\n",
      "On batch 850\n",
      "On batch 900\n",
      "On batch 950\n",
      "On batch 1000\n",
      "On batch 1050\n",
      "Ending epoch 7: Average loss 0.01757\n",
      "On batch 0\n",
      "On batch 50\n",
      "On batch 100\n",
      "On batch 150\n",
      "On batch 200\n",
      "On batch 250\n",
      "On batch 300\n",
      "On batch 350\n",
      "On batch 400\n",
      "On batch 450\n",
      "On batch 500\n",
      "On batch 550\n",
      "On batch 600\n",
      "On batch 650\n",
      "On batch 700\n",
      "On batch 750\n",
      "On batch 800\n",
      "On batch 850\n",
      "On batch 900\n",
      "On batch 950\n",
      "On batch 1000\n",
      "On batch 1050\n",
      "Ending epoch 8: Average loss 0.0132135\n",
      "On batch 0\n",
      "On batch 50\n",
      "On batch 100\n",
      "On batch 150\n",
      "On batch 200\n",
      "On batch 250\n",
      "On batch 300\n",
      "On batch 350\n",
      "On batch 400\n",
      "On batch 450\n",
      "On batch 500\n",
      "On batch 550\n",
      "On batch 600\n",
      "On batch 650\n",
      "On batch 700\n",
      "On batch 750\n",
      "On batch 800\n",
      "On batch 850\n",
      "On batch 900\n",
      "On batch 950\n",
      "On batch 1000\n",
      "On batch 1050\n",
      "Loggin\n",
      "Ending epoch 9: Average loss 0.0121854\n",
      "TIMING: model fitting took 77.903 s\n"
     ]
    }
   ],
   "source": [
    "tg.fit(train, nb_epoch=10)\n",
    "tg.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n",
      "class 0:auc=0.99987578265\n",
      "class 1:auc=0.999975981083\n",
      "class 2:auc=0.99987010958\n",
      "class 3:auc=0.999980197583\n",
      "class 4:auc=0.999985348139\n",
      "class 5:auc=0.999889990331\n",
      "class 6:auc=0.999762644083\n",
      "class 7:auc=0.999936670072\n",
      "class 8:auc=0.999936085657\n",
      "class 9:auc=0.999968609514\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import numpy as np\n",
    "\n",
    "print(\"Validation\")\n",
    "prediction = np.squeeze(tg.predict_on_batch(valid.X))\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(10):\n",
    "    fpr[i], tpr[i], thresh = roc_curve(valid.y[:, i], prediction[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    print(\"class %s:auc=%s\" % (i, roc_auc[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
