{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pdb off\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "__author__ = \"Joseph Gomes\"\n",
    "__copyright__ = \"Copyright 2016, Stanford University\"\n",
    "__license__ = \"LGPL\"\n",
    "\n",
    "import os\n",
    "import unittest\n",
    "import tempfile\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import numpy.random\n",
    "\n",
    "from deepchem.utils.evaluate import Evaluator\n",
    "from deepchem.featurizers.featurize import DataFeaturizer\n",
    "from deepchem.featurizers.featurize import FeaturizedSamples\n",
    "from deepchem.hyperparameters import HyperparamOpt\n",
    "from deepchem.models import Model\n",
    "from deepchem.models.deep import SingleTaskDNN\n",
    "from deepchem.models.standard import SklearnModel\n",
    "from deepchem.transformers import NormalizationTransformer\n",
    "from deepchem.utils.dataset import Dataset\n",
    "from deepchem.utils.evaluate import Evaluator\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating temporary directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_dir = tempfile.mkdtemp()\n",
    "samples_dir = tempfile.mkdtemp()\n",
    "train_dir = tempfile.mkdtemp()\n",
    "valid_dir = tempfile.mkdtemp()\n",
    "test_dir = tempfile.mkdtemp()\n",
    "model_dir = tempfile.mkdtemp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up model variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "splittype = \"random\"\n",
    "compound_featurizers = []\n",
    "complex_featurizers = []\n",
    "feature_types = [\"user_specified_features\"]\n",
    "user_specified_features = [\"evals\"]\n",
    "task_types = {\"u0_atom\": \"regression\"}\n",
    "input_file = \"../datasets/gdb7k.pkl.gz\"\n",
    "smiles_field = \"smiles\"\n",
    "protein_pdb_field = None\n",
    "ligand_pdb_field = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load featurized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featurizers = compound_featurizers + complex_featurizers\n",
    "featurizer = DataFeaturizer(tasks=task_types.keys(),\n",
    "                            smiles_field=smiles_field,\n",
    "                            protein_pdb_field=protein_pdb_field,\n",
    "                            ligand_pdb_field=ligand_pdb_field,\n",
    "                            compound_featurizers=compound_featurizers,\n",
    "                            complex_featurizers=complex_featurizers,\n",
    "                            user_specified_features=user_specified_features,\n",
    "                            verbose=False)\n",
    "featurized_samples = featurizer.featurize(input_file, feature_dir, samples_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform Train, Validation, and Testing Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_samples, valid_samples, test_samples = featurized_samples.train_valid_test_split(\n",
    "    splittype, train_dir, valid_dir, test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joegomes/deepchem/deepchem/utils/dataset.py:232: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  if features[feature_ind] == \"\":\n",
      "/home/joegomes/deepchem/deepchem/utils/dataset.py:240: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  if y[ind, task] == \"\":\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Dataset(data_dir=train_dir, samples=train_samples, \n",
    "                        featurizers=featurizers, tasks=task_types.keys(),\n",
    "                        use_user_specified_features=True)\n",
    "valid_dataset = Dataset(data_dir=valid_dir, samples=valid_samples, \n",
    "                        featurizers=featurizers, tasks=task_types.keys(),\n",
    "                        use_user_specified_features=True)\n",
    "test_dataset = Dataset(data_dir=test_dir, samples=test_samples, \n",
    "                       featurizers=featurizers, tasks=task_types.keys(),\n",
    "                       use_user_specified_features=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_transformers = [NormalizationTransformer(transform_X=True, dataset=train_dataset)]\n",
    "output_transformers = [NormalizationTransformer(transform_y=True, dataset=train_dataset)]\n",
    "transformers = input_transformers + output_transformers\n",
    "for transformer in transformers:\n",
    "    transformer.transform(train_dataset)\n",
    "for transformer in transformers:\n",
    "    transformer.transform(valid_dataset)\n",
    "for transformer in transformers:\n",
    "    transformer.transform(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Fit Random Forest with hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0/8, Metric mae, Validation set 0: 14.192981\n",
      "\tbest_validation_score so  far: 14.192981\n",
      "Model 1/8, Metric mae, Validation set 1: 17.662740\n",
      "\tbest_validation_score so  far: 14.192981\n",
      "Model 2/8, Metric mae, Validation set 2: 18.310513\n",
      "\tbest_validation_score so  far: 14.192981\n",
      "Model 3/8, Metric mae, Validation set 3: 14.027211\n",
      "\tbest_validation_score so  far: 14.027211\n",
      "Model 4/8, Metric mae, Validation set 4: 13.244072\n",
      "\tbest_validation_score so  far: 13.244072\n",
      "Model 5/8, Metric mae, Validation set 5: 16.299018\n",
      "\tbest_validation_score so  far: 13.244072\n",
      "Model 6/8, Metric mae, Validation set 6: 15.994767\n",
      "\tbest_validation_score so  far: 13.244072\n",
      "Model 7/8, Metric mae, Validation set 7: 13.336670\n",
      "\tbest_validation_score so  far: 13.244072\n",
      "Best hyperparameters: [(u'n_estimators', 100), (u'data_shape', (23,)), (u'max_features', u'auto')]\n",
      "train_score: 5.061809\n",
      "validation_score: 13.244072\n"
     ]
    }
   ],
   "source": [
    "def model_builder(task_types, params_dict, verbosity):\n",
    "    n_estimators = params_dict[\"n_estimators\"]\n",
    "    max_features = params_dict[\"max_features\"]\n",
    "    return SklearnModel(\n",
    "        task_types, params_dict,\n",
    "        model_instance=RandomForestRegressor(n_estimators=n_estimators,\n",
    "                                             max_features=max_features))\n",
    "params_dict = {\n",
    "    \"n_estimators\": [10, 100],\n",
    "    \"data_shape\": [train_dataset.get_data_shape()],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\", None],\n",
    "    }\n",
    "optimizer = HyperparamOpt(model_builder, task_types)\n",
    "best_rf, best_rf_hyperparams, all_rf_results = optimizer.hyperparam_search(\n",
    "    params_dict, train_dataset, valid_dataset, output_transformers, metric=\"mae\", use_max=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute train/valid/test set mean absolute error for best RF hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Train set MAE 5.061809\n",
      "RF Valid set MAE 13.244072\n",
      "RF Test set MAE error 12.989110\n"
     ]
    }
   ],
   "source": [
    "rf_train_csv_out = \"rf_train_regressor.csv\"\n",
    "rf_train_stats_out = \"rf_train_stats_regressor.txt\"\n",
    "rf_train_evaluator = Evaluator(best_rf, train_dataset, output_transformers)\n",
    "rf_train_df, rf_train_mae = rf_train_evaluator.compute_model_performance(\n",
    "    rf_train_csv_out, rf_train_stats_out)\n",
    "rf_train_mae = rf_train_mae.iloc[0][\"mae\"]\n",
    "print(\"RF Train set MAE %f\" % (rf_train_mae))\n",
    "\n",
    "rf_valid_csv_out = \"rf_valid_regressor.csv\"\n",
    "rf_valid_stats_out = \"rf_valid_stats_regressor.txt\"\n",
    "rf_valid_evaluator = Evaluator(best_rf, valid_dataset, output_transformers)\n",
    "rf_valid_df, rf_valid_mae = rf_valid_evaluator.compute_model_performance(\n",
    "    rf_valid_csv_out, rf_valid_stats_out)\n",
    "rf_valid_mae = rf_valid_mae.iloc[0][\"mae\"]\n",
    "print(\"RF Valid set MAE %f\" % (rf_valid_mae))\n",
    "\n",
    "rf_test_csv_out = \"rf_test_regressor.csv\"\n",
    "rf_test_stats_out = \"rf_test_stats_regressor.txt\"\n",
    "rf_test_evaluator = Evaluator(best_rf, test_dataset, output_transformers)\n",
    "rf_test_df, rf_test_mae = rf_test_evaluator.compute_model_performance(\n",
    "    rf_test_csv_out, rf_test_stats_out)\n",
    "rf_test_mae = rf_test_mae.iloc[0][\"mae\"]\n",
    "print(\"RF Test set MAE error %f\" % (rf_test_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit Kernal Ridge Regression with hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0/32, Metric mae, Validation set 0: 17.163126\n",
      "\tbest_validation_score so  far: 17.163126\n",
      "Model 1/32, Metric mae, Validation set 1: 20.604338\n",
      "\tbest_validation_score so  far: 17.163126\n",
      "Model 2/32, Metric mae, Validation set 2: 25.012712\n",
      "\tbest_validation_score so  far: 17.163126\n",
      "Model 3/32, Metric mae, Validation set 3: 28.863665\n",
      "\tbest_validation_score so  far: 17.163126\n",
      "Model 4/32, Metric mae, Validation set 4: 11.357195\n",
      "\tbest_validation_score so  far: 11.357195\n",
      "Model 5/32, Metric mae, Validation set 5: 13.396137\n",
      "\tbest_validation_score so  far: 11.357195\n",
      "Model 6/32, Metric mae, Validation set 6: 16.528441\n",
      "\tbest_validation_score so  far: 11.357195\n",
      "Model 7/32, Metric mae, Validation set 7: 20.507368\n",
      "\tbest_validation_score so  far: 11.357195\n",
      "Model 8/32, Metric mae, Validation set 8: 9.390308\n",
      "\tbest_validation_score so  far: 9.390308\n",
      "Model 9/32, Metric mae, Validation set 9: 9.652509\n",
      "\tbest_validation_score so  far: 9.390308\n",
      "Model 10/32, Metric mae, Validation set 10: 10.695947\n",
      "\tbest_validation_score so  far: 9.390308\n",
      "Model 11/32, Metric mae, Validation set 11: 13.438048\n",
      "\tbest_validation_score so  far: 9.390308\n",
      "Model 12/32, Metric mae, Validation set 12: 11.271591\n",
      "\tbest_validation_score so  far: 9.390308\n",
      "Model 13/32, Metric mae, Validation set 13: 9.534297\n",
      "\tbest_validation_score so  far: 9.390308\n",
      "Model 14/32, Metric mae, Validation set 14: 9.493804\n",
      "\tbest_validation_score so  far: 9.390308\n",
      "Model 15/32, Metric mae, Validation set 15: 11.109265\n",
      "\tbest_validation_score so  far: 9.390308\n",
      "Model 16/32, Metric mae, Validation set 16: 9.575545\n",
      "\tbest_validation_score so  far: 9.390308\n",
      "Model 17/32, Metric mae, Validation set 17: 10.056490\n",
      "\tbest_validation_score so  far: 9.390308\n",
      "Model 18/32, Metric mae, Validation set 18: 13.275990\n",
      "\tbest_validation_score so  far: 9.390308\n",
      "Model 19/32, Metric mae, Validation set 19: 22.530551\n",
      "\tbest_validation_score so  far: 9.390308\n",
      "Model 20/32, Metric mae, Validation set 20: 9.570758\n",
      "\tbest_validation_score so  far: 9.390308\n",
      "Model 21/32, Metric mae, Validation set 21: 9.137386\n",
      "\tbest_validation_score so  far: 9.137386\n",
      "Model 22/32, Metric mae, Validation set 22: 9.792765\n",
      "\tbest_validation_score so  far: 9.137386\n",
      "Model 23/32, Metric mae, Validation set 23: 13.218176\n",
      "\tbest_validation_score so  far: 9.137386\n",
      "Model 24/32, Metric mae, Validation set 24: 9.371906\n",
      "\tbest_validation_score so  far: 9.137386\n",
      "Model 25/32, Metric mae, Validation set 25: 8.878904\n",
      "\tbest_validation_score so  far: 8.878904\n",
      "Model 26/32, Metric mae, Validation set 26: 8.637119\n",
      "\tbest_validation_score so  far: 8.637119\n",
      "Model 27/32, Metric mae, Validation set 27: 9.315361\n",
      "\tbest_validation_score so  far: 8.637119\n",
      "Model 28/32, Metric mae, Validation set 28: 8.830955\n",
      "\tbest_validation_score so  far: 8.637119\n",
      "Model 29/32, Metric mae, Validation set 29: 8.821177\n",
      "\tbest_validation_score so  far: 8.637119\n",
      "Model 30/32, Metric mae, Validation set 30: 8.762764\n",
      "\tbest_validation_score so  far: 8.637119\n",
      "Model 31/32, Metric mae, Validation set 31: 8.884506\n",
      "\tbest_validation_score so  far: 8.637119\n",
      "Best hyperparameters: [(u'kernel', u'laplacian'), (u'gamma', 0.01), (u'alpha', 0.01)]\n",
      "train_score: 6.467041\n",
      "validation_score: 8.637119\n"
     ]
    }
   ],
   "source": [
    "def model_builder(task_types, params_dict, verbosity):\n",
    "    kernel = params_dict[\"kernel\"]\n",
    "    alpha = params_dict[\"alpha\"]\n",
    "    gamma = params_dict[\"gamma\"]\n",
    "    return SklearnModel(\n",
    "        task_types, params_dict,\n",
    "        model_instance=KernelRidge(alpha=alpha,kernel=kernel,gamma=gamma))\n",
    "params_dict = {\n",
    "    \"kernel\": [\"rbf\", \"laplacian\"],\n",
    "    \"alpha\": [0.0001,0.001,0.01,0.1],\n",
    "    \"gamma\": [0.0001,0.001,0.01,0.1]\n",
    "    }\n",
    "optimizer = HyperparamOpt(model_builder, task_types)\n",
    "best_krr, best_krr_hyperparams, all_krr_results = optimizer.hyperparam_search(\n",
    "    params_dict, train_dataset, valid_dataset, output_transformers, metric=\"mae\", use_max=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute train/valid/test set mean absolute error for best KRR hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KRR Train set MAE 6.467041\n",
      "KRR Valid set MAE 8.637119\n",
      "KRR Test set MAE error 8.990674\n"
     ]
    }
   ],
   "source": [
    "krr_train_csv_out = \"krr_train_regressor.csv\"\n",
    "krr_train_stats_out = \"krr_train_stats_regressor.txt\"\n",
    "krr_train_evaluator = Evaluator(best_krr, train_dataset, output_transformers)\n",
    "krr_train_df, krr_train_mae = krr_train_evaluator.compute_model_performance(\n",
    "    krr_train_csv_out, krr_train_stats_out)\n",
    "krr_train_mae = krr_train_mae.iloc[0][\"mae\"]\n",
    "print(\"KRR Train set MAE %f\" % (krr_train_mae))\n",
    "\n",
    "krr_valid_csv_out = \"krr_valid_regressor.csv\"\n",
    "krr_valid_stats_out = \"krr_valid_stats_regressor.txt\"\n",
    "krr_valid_evaluator = Evaluator(best_krr, valid_dataset, output_transformers)\n",
    "krr_valid_df, krr_valid_mae = krr_valid_evaluator.compute_model_performance(\n",
    "    krr_valid_csv_out, krr_valid_stats_out)\n",
    "krr_valid_mae = krr_valid_mae.iloc[0][\"mae\"]\n",
    "print(\"KRR Valid set MAE %f\" % (krr_valid_mae))\n",
    "\n",
    "krr_test_csv_out = \"krr_test_regressor.csv\"\n",
    "krr_test_stats_out = \"krr_test_stats_regressor.txt\"\n",
    "krr_test_evaluator = Evaluator(best_krr, test_dataset, output_transformers)\n",
    "krr_test_df, krr_test_mae = krr_test_evaluator.compute_model_performance(\n",
    "    krr_test_csv_out, krr_test_stats_out)\n",
    "krr_test_mae = krr_test_mae.iloc[0][\"mae\"]\n",
    "print(\"KRR Test set MAE error %f\" % (krr_test_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit Single-task DNN with hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0/50, Metric mae, Validation set 0: nan\n",
      "\tbest_validation_score so  far: inf\n",
      "Model 1/50, Metric mae, Validation set 1: 19.064085\n",
      "\tbest_validation_score so  far: 19.064085\n",
      "Model 2/50, Metric mae, Validation set 2: 18.373328\n",
      "\tbest_validation_score so  far: 18.373328\n",
      "Model 3/50, Metric mae, Validation set 3: 21.892876\n",
      "\tbest_validation_score so  far: 18.373328\n",
      "Model 4/50, Metric mae, Validation set 4: 18.118478\n",
      "\tbest_validation_score so  far: 18.118478\n",
      "Model 5/50, Metric mae, Validation set 5: nan\n",
      "\tbest_validation_score so  far: 18.118478\n",
      "Model 6/50, Metric mae, Validation set 6: 19.239610\n",
      "\tbest_validation_score so  far: 18.118478\n",
      "Model 7/50, Metric mae, Validation set 7: 18.062948\n",
      "\tbest_validation_score so  far: 18.062948\n",
      "Model 8/50, Metric mae, Validation set 8: 20.640809\n",
      "\tbest_validation_score so  far: 18.062948\n",
      "Model 9/50, Metric mae, Validation set 9: 21.097265\n",
      "\tbest_validation_score so  far: 18.062948\n",
      "Model 10/50, Metric mae, Validation set 10: nan\n",
      "\tbest_validation_score so  far: 18.062948\n",
      "Model 11/50, Metric mae, Validation set 11: 20.325680\n",
      "\tbest_validation_score so  far: 18.062948\n",
      "Model 12/50, Metric mae, Validation set 12: 18.724774\n",
      "\tbest_validation_score so  far: 18.062948\n",
      "Model 13/50, Metric mae, Validation set 13: 21.641100\n",
      "\tbest_validation_score so  far: 18.062948\n",
      "Model 14/50, Metric mae, Validation set 14: 17.513500\n",
      "\tbest_validation_score so  far: 17.513500\n",
      "Model 15/50, Metric mae, Validation set 15: nan\n",
      "\tbest_validation_score so  far: 17.513500\n",
      "Model 16/50, Metric mae, Validation set 16: 19.427387\n",
      "\tbest_validation_score so  far: 17.513500\n",
      "Model 17/50, Metric mae, Validation set 17: 18.082895\n",
      "\tbest_validation_score so  far: 17.513500\n",
      "Model 18/50, Metric mae, Validation set 18: 20.989158\n",
      "\tbest_validation_score so  far: 17.513500\n",
      "Model 19/50, Metric mae, Validation set 19: 19.412126\n",
      "\tbest_validation_score so  far: 17.513500\n",
      "Model 20/50, Metric mae, Validation set 20: nan\n",
      "\tbest_validation_score so  far: 17.513500\n",
      "Model 21/50, Metric mae, Validation set 21: 19.056597\n",
      "\tbest_validation_score so  far: 17.513500\n",
      "Model 22/50, Metric mae, Validation set 22: 17.862962\n",
      "\tbest_validation_score so  far: 17.513500\n",
      "Model 23/50, Metric mae, Validation set 23: 20.875660\n",
      "\tbest_validation_score so  far: 17.513500\n",
      "Model 24/50, Metric mae, Validation set 24: 17.192917\n",
      "\tbest_validation_score so  far: 17.192917\n",
      "Model 25/50, Metric mae, Validation set 25: nan\n",
      "\tbest_validation_score so  far: 17.192917\n",
      "Model 26/50, Metric mae, Validation set 26: 19.438970\n",
      "\tbest_validation_score so  far: 17.192917\n",
      "Model 27/50, Metric mae, Validation set 27: 17.578085\n",
      "\tbest_validation_score so  far: 17.192917\n",
      "Model 28/50, Metric mae, Validation set 28: 21.458525"
     ]
    }
   ],
   "source": [
    "np.random.seed()\n",
    "params_dict = {\"activation\": [\"relu\"],\n",
    "                \"momentum\": [.9],\n",
    "                \"batch_size\": [50],\n",
    "                \"init\": [\"glorot_uniform\"],\n",
    "                \"data_shape\": [train_dataset.get_data_shape()],\n",
    "                \"learning_rate\": np.power(10., np.random.uniform(-5, -2, size=5)),\n",
    "                \"decay\": np.power(10., np.random.uniform(-6, -4, size=5)),\n",
    "                \"nb_hidden\": [1000],\n",
    "                \"nb_epoch\": [50],\n",
    "                \"nesterov\": [True],\n",
    "                \"dropout\": [.1],\n",
    "                \"nb_layers\": [1, 2],\n",
    "                \"batchnorm\": [False],\n",
    "              }\n",
    "\n",
    "optimizer = HyperparamOpt(SingleTaskDNN, task_types)\n",
    "best_dnn, best_hyperparams, all_results = optimizer.hyperparam_search(\n",
    "    params_dict, train_dataset, valid_dataset, output_transformers, metric=\"mae\", \n",
    "    use_max=False, verbosity=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute train/valid/test set mean absolute error for best DNN hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dnn_train_csv_out = \"dnn_train_regressor.csv\"\n",
    "dnn_train_stats_out = \"dnn_train_regressor_stats.txt\"\n",
    "dnn_train_evaluator = Evaluator(best_dnn, train_dataset, output_transformers)\n",
    "dnn_train_df, dnn_train_mae = dnn_train_evaluator.compute_model_performance(\n",
    "    dnn_train_csv_out, dnn_train_stats_out)\n",
    "dnn_train_mae = dnn_train_mae.iloc[0][\"mae\"]\n",
    "print(\"DNN Train set MAE error %f\" % (dnn_train_mae))\n",
    "\n",
    "dnn_valid_csv_out = \"dnn_valid_regressor.csv\"\n",
    "dnn_valid_stats_out = \"dnn_valid_regressor_stats.txt\"\n",
    "dnn_valid_evaluator = Evaluator(best_dnn, valid_dataset, output_transformers)\n",
    "dnn_valid_df, dnn_valid_mae = dnn_valid_evaluator.compute_model_performance(\n",
    "    dnn_valid_csv_out, dnn_valid_stats_out)\n",
    "dnn_valid_mae = dnn_valid_mae.iloc[0][\"mae\"]\n",
    "print(\"DNN Valid set MAE error %f\" % (dnn_valid_mae))\n",
    "\n",
    "dnn_test_csv_out = \"dnn_test_regressor.csv\"\n",
    "dnn_test_stats_out = \"dnn_test_regressor_stats.txt\"\n",
    "dnn_test_evaluator = Evaluator(best_dnn, test_dataset, output_transformers)\n",
    "dnn_test_df, dnn_test_mae = dnn_test_evaluator.compute_model_performance(\n",
    "    dnn_test_csv_out, dnn_test_stats_out)\n",
    "dnn_test_mae = dnn_test_mae.iloc[0][\"mae\"]\n",
    "print(\"DNN Test set MAE error %f\" % (dnn_test_mae))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
