{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial Part 2: Learning MNIST Digit Classifiers\n",
    "\n",
    "In the previous tutorial, we learned some basics of how to load data into DeepChem and how to use the basic DeepChem objects to load and manipulate this data. In this tutorial, you'll put the parts together and learn how to train a basic image classification model in DeepChem. You might ask, why are we bothering to learn this material in DeepChem? Part of the reason is that image processing is an increasingly important part of AI for the life sciences. So learning how to train image processing models will be very useful for using some of the more advanced DeepChem features.\n",
    "\n",
    "The MNIST dataset contains handwritten digits along with their human annotated labels. The learning challenge for this dataset is to train a model that maps the digit image to its true label. MNIST has been a standard benchmark for machine learning for decades at this point. \n",
    "\n",
    "![MNIST](mnist_examples.png)\n",
    "\n",
    "## Setup\n",
    "\n",
    "We recommend running this tutorial on Google colab. You'll need to run the following cell of installation commands on Colab to get your environment set up. If you'd rather run the tutorial locally, make sure you don't run these commands (since they'll download and install a new Anaconda python setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -c https://repo.anaconda.com/archive/Anaconda3-2019.10-Linux-x86_64.sh\n",
    "!chmod +x Anaconda3-2019.10-Linux-x86_64.sh\n",
    "!bash ./Anaconda3-2019.10-Linux-x86_64.sh -b -f -p /usr/local\n",
    "!conda install -y -c deepchem -c rdkit -c conda-forge -c omnia deepchem-gpu=2.3.0\n",
    "import sys\n",
    "sys.path.append('/usr/local/lib/python3.7/site-packages/')\n",
    "import deepchem as dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# TODO: This is deprecated. Let's replace with a DeepChem native loader for maintainability.\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepchem as dc\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Reshape, Conv2D, Flatten, Dense, Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dc.data.NumpyDataset(mnist.train.images, mnist.train.labels)\n",
    "valid = dc.data.NumpyDataset(mnist.validation.images, mnist.validation.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model = tf.keras.Sequential([\n",
    "    Reshape((28, 28, 1)),\n",
    "    Conv2D(filters=32, kernel_size=5, activation=tf.nn.relu),\n",
    "    Conv2D(filters=64, kernel_size=5, activation=tf.nn.relu),\n",
    "    Flatten(),\n",
    "    Dense(1024, activation=tf.nn.relu),\n",
    "    Dense(10),\n",
    "    Softmax()\n",
    "])\n",
    "model = dc.models.KerasModel(keras_model, dc.models.losses.CategoricalCrossEntropy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train, nb_epoch=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n",
      "class 0:auc=0.9998836328172079\n",
      "class 1:auc=0.9999571662641497\n",
      "class 2:auc=0.9998310516219043\n",
      "class 3:auc=0.9999563446718672\n",
      "class 4:auc=0.9999418111793702\n",
      "class 5:auc=0.9995639983771051\n",
      "class 6:auc=0.9998478260194437\n",
      "class 7:auc=0.9998357507660879\n",
      "class 8:auc=0.9999599342922393\n",
      "class 9:auc=0.9998551553268534\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import numpy as np\n",
    "\n",
    "print(\"Validation\")\n",
    "prediction = np.squeeze(model.predict_on_batch(valid.X))\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(10):\n",
    "    fpr[i], tpr[i], thresh = roc_curve(valid.y[:, i], prediction[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    print(\"class %s:auc=%s\" % (i, roc_auc[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
